Test KL-divergence calibration pass: 
#[version = "0.0.5"]
def @main(%input: Tensor[(2, 3, 224, 224), float32]) -> Tensor[(2, 1000), float32] {
  %0 = qnn.quantize(%input, 0.1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(2, 3, 224, 224), int8] */;
  %1 = nn.pad(%0, pad_width=[[0, 0], [0, 0], [3, 3], [3, 3]]) /* ty=Tensor[(2, 3, 230, 230), int8] */;
  %2 = qnn.quantize(meta[relay.Constant][0] /* ty=Tensor[(64, 3, 7, 7), float32] */, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(64, 3, 7, 7), int8] */;
  %3 = qnn.conv2d(%1, %2, 0 /* ty=int32 */, 0 /* ty=int32 */, 0.1f /* ty=float32 */, 1f /* ty=float32 */, strides=[2, 2], padding=[0, 0, 0, 0], channels=64, kernel_size=[7, 7], out_dtype="int32") /* ty=Tensor[(2, 64, 112, 112), int32] */;
  %4 = qnn.dequantize(%3, 0.1f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(2, 64, 112, 112), float32] */;
  %5 = qnn.quantize(%4, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(2, 64, 112, 112), int8] */;
  %6 = qnn.quantize(meta[relay.Constant][1] /* ty=Tensor[(64, 1, 1), float32] */, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(64, 1, 1), int8] */;
  %7 = qnn.add(%5, %6, 1f /* ty=float32 */, 0 /* ty=int32 */, 1f /* ty=float32 */, 0 /* ty=int32 */, 2f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(2, 64, 112, 112), int8] */;
  %8 = qnn.dequantize(%7, 2f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(2, 64, 112, 112), float32] */;
  %9 = nn.relu(%8) /* ty=Tensor[(2, 64, 112, 112), float32] */;
  %10 = nn.max_pool2d(%9, pool_size=[3, 3], strides=[2, 2], padding=[1, 1, 1, 1]) /* ty=Tensor[(2, 64, 56, 56), float32] */;
  %11 = qnn.quantize(%10, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(2, 64, 56, 56), int8] */;
  %12 = nn.pad(%11, pad_width=[[0, 0], [0, 0], [1, 1], [1, 1]]) /* ty=Tensor[(2, 64, 58, 58), int8] */;
  %13 = qnn.quantize(meta[relay.Constant][2] /* ty=Tensor[(64, 64, 3, 3), float32] */, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(64, 64, 3, 3), int8] */;
  %14 = qnn.conv2d(%12, %13, 0 /* ty=int32 */, 0 /* ty=int32 */, 1f /* ty=float32 */, 1f /* ty=float32 */, padding=[0, 0, 0, 0], channels=64, kernel_size=[3, 3], out_dtype="int32") /* ty=Tensor[(2, 64, 56, 56), int32] */;
  %15 = qnn.dequantize(%14, 1f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(2, 64, 56, 56), float32] */;
  %16 = qnn.quantize(%15, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(2, 64, 56, 56), int8] */;
  %17 = qnn.quantize(meta[relay.Constant][3] /* ty=Tensor[(64, 1, 1), float32] */, 0.2f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(64, 1, 1), int8] */;
  %18 = qnn.add(%16, %17, 1f /* ty=float32 */, 0 /* ty=int32 */, 0.2f /* ty=float32 */, 0 /* ty=int32 */, 1.2f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(2, 64, 56, 56), int8] */;
  %19 = qnn.dequantize(%18, 1.2f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(2, 64, 56, 56), float32] */;
  %20 = nn.relu(%19) /* ty=Tensor[(2, 64, 56, 56), float32] */;
  %21 = qnn.quantize(%20, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(2, 64, 56, 56), int8] */;
  %22 = nn.pad(%21, pad_width=[[0, 0], [0, 0], [1, 1], [1, 1]]) /* ty=Tensor[(2, 64, 58, 58), int8] */;
  %23 = qnn.quantize(meta[relay.Constant][4] /* ty=Tensor[(64, 64, 3, 3), float32] */, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(64, 64, 3, 3), int8] */;
  %24 = qnn.conv2d(%22, %23, 0 /* ty=int32 */, 0 /* ty=int32 */, 1f /* ty=float32 */, 1f /* ty=float32 */, padding=[0, 0, 0, 0], channels=64, kernel_size=[3, 3], out_dtype="int32") /* ty=Tensor[(2, 64, 56, 56), int32] */;
  %25 = qnn.dequantize(%24, 1f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(2, 64, 56, 56), float32] */;
  %26 = qnn.quantize(%25, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(2, 64, 56, 56), int8] */;
  %27 = qnn.quantize(meta[relay.Constant][5] /* ty=Tensor[(64, 1, 1), float32] */, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(64, 1, 1), int8] */;
  %28 = qnn.add(%26, %27, 1f /* ty=float32 */, 0 /* ty=int32 */, 1f /* ty=float32 */, 0 /* ty=int32 */, 2f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(2, 64, 56, 56), int8] */;
  %29 = qnn.dequantize(%28, 2f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(2, 64, 56, 56), float32] */;
  %30 = qnn.quantize(%29, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(2, 64, 56, 56), int8] */;
  %31 = qnn.quantize(%10, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(2, 64, 56, 56), int8] */;
  %32 = qnn.add(%30, %31, 1f /* ty=float32 */, 0 /* ty=int32 */, 1f /* ty=float32 */, 0 /* ty=int32 */, 2f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(2, 64, 56, 56), int8] */;
  %33 = qnn.dequantize(%32, 2f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(2, 64, 56, 56), float32] */;
  %34 = nn.relu(%33) /* ty=Tensor[(2, 64, 56, 56), float32] */;
  %35 = qnn.quantize(%34, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(2, 64, 56, 56), int8] */;
  %36 = nn.pad(%35, pad_width=[[0, 0], [0, 0], [1, 1], [1, 1]]) /* ty=Tensor[(2, 64, 58, 58), int8] */;
  %37 = qnn.quantize(meta[relay.Constant][6] /* ty=Tensor[(64, 64, 3, 3), float32] */, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(64, 64, 3, 3), int8] */;
  %38 = qnn.conv2d(%36, %37, 0 /* ty=int32 */, 0 /* ty=int32 */, 1f /* ty=float32 */, 1f /* ty=float32 */, padding=[0, 0, 0, 0], channels=64, kernel_size=[3, 3], out_dtype="int32") /* ty=Tensor[(2, 64, 56, 56), int32] */;
  %39 = qnn.dequantize(%38, 1f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(2, 64, 56, 56), float32] */;
  %40 = qnn.quantize(%39, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(2, 64, 56, 56), int8] */;
  %41 = qnn.quantize(meta[relay.Constant][7] /* ty=Tensor[(64, 1, 1), float32] */, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(64, 1, 1), int8] */;
  %42 = qnn.add(%40, %41, 1f /* ty=float32 */, 0 /* ty=int32 */, 1f /* ty=float32 */, 0 /* ty=int32 */, 2f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(2, 64, 56, 56), int8] */;
  %43 = qnn.dequantize(%42, 2f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(2, 64, 56, 56), float32] */;
  %44 = nn.relu(%43) /* ty=Tensor[(2, 64, 56, 56), float32] */;
  %45 = qnn.quantize(%44, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(2, 64, 56, 56), int8] */;
  %46 = nn.pad(%45, pad_width=[[0, 0], [0, 0], [1, 1], [1, 1]]) /* ty=Tensor[(2, 64, 58, 58), int8] */;
  %47 = qnn.quantize(meta[relay.Constant][8] /* ty=Tensor[(64, 64, 3, 3), float32] */, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(64, 64, 3, 3), int8] */;
  %48 = qnn.conv2d(%46, %47, 0 /* ty=int32 */, 0 /* ty=int32 */, 1f /* ty=float32 */, 1f /* ty=float32 */, padding=[0, 0, 0, 0], channels=64, kernel_size=[3, 3], out_dtype="int32") /* ty=Tensor[(2, 64, 56, 56), int32] */;
  %49 = qnn.dequantize(%48, 1f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(2, 64, 56, 56), float32] */;
  %50 = qnn.quantize(%49, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(2, 64, 56, 56), int8] */;
  %51 = qnn.quantize(meta[relay.Constant][9] /* ty=Tensor[(64, 1, 1), float32] */, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(64, 1, 1), int8] */;
  %52 = qnn.add(%50, %51, 1f /* ty=float32 */, 0 /* ty=int32 */, 1f /* ty=float32 */, 0 /* ty=int32 */, 2f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(2, 64, 56, 56), int8] */;
  %53 = qnn.dequantize(%52, 2f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(2, 64, 56, 56), float32] */;
  %54 = qnn.quantize(%53, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(2, 64, 56, 56), int8] */;
  %55 = qnn.quantize(%34, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(2, 64, 56, 56), int8] */;
  %56 = qnn.add(%54, %55, 1f /* ty=float32 */, 0 /* ty=int32 */, 1f /* ty=float32 */, 0 /* ty=int32 */, 2f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(2, 64, 56, 56), int8] */;
  %57 = qnn.dequantize(%56, 2f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(2, 64, 56, 56), float32] */;
  %58 = nn.relu(%57) /* ty=Tensor[(2, 64, 56, 56), float32] */;
  %59 = qnn.quantize(%58, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(2, 64, 56, 56), int8] */;
  %60 = nn.pad(%59, pad_width=[[0, 0], [0, 0], [1, 1], [1, 1]]) /* ty=Tensor[(2, 64, 58, 58), int8] */;
  %61 = qnn.quantize(meta[relay.Constant][10] /* ty=Tensor[(128, 64, 3, 3), float32] */, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(128, 64, 3, 3), int8] */;
  %62 = qnn.conv2d(%60, %61, 0 /* ty=int32 */, 0 /* ty=int32 */, 1f /* ty=float32 */, 1f /* ty=float32 */, strides=[2, 2], padding=[0, 0, 0, 0], channels=128, kernel_size=[3, 3], out_dtype="int32") /* ty=Tensor[(2, 128, 28, 28), int32] */;
  %63 = qnn.dequantize(%62, 1f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(2, 128, 28, 28), float32] */;
  %64 = qnn.quantize(%63, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(2, 128, 28, 28), int8] */;
  %65 = qnn.quantize(meta[relay.Constant][11] /* ty=Tensor[(128, 1, 1), float32] */, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(128, 1, 1), int8] */;
  %66 = qnn.add(%64, %65, 1f /* ty=float32 */, 0 /* ty=int32 */, 1f /* ty=float32 */, 0 /* ty=int32 */, 2f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(2, 128, 28, 28), int8] */;
  %67 = qnn.dequantize(%66, 2f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(2, 128, 28, 28), float32] */;
  %68 = nn.relu(%67) /* ty=Tensor[(2, 128, 28, 28), float32] */;
  %69 = qnn.quantize(%68, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(2, 128, 28, 28), int8] */;
  %70 = nn.pad(%69, pad_width=[[0, 0], [0, 0], [1, 1], [1, 1]]) /* ty=Tensor[(2, 128, 30, 30), int8] */;
  %71 = qnn.quantize(meta[relay.Constant][12] /* ty=Tensor[(128, 128, 3, 3), float32] */, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(128, 128, 3, 3), int8] */;
  %72 = qnn.conv2d(%70, %71, 0 /* ty=int32 */, 0 /* ty=int32 */, 1f /* ty=float32 */, 1f /* ty=float32 */, padding=[0, 0, 0, 0], channels=128, kernel_size=[3, 3], out_dtype="int32") /* ty=Tensor[(2, 128, 28, 28), int32] */;
  %73 = qnn.dequantize(%72, 1f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(2, 128, 28, 28), float32] */;
  %74 = qnn.quantize(%73, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(2, 128, 28, 28), int8] */;
  %75 = qnn.quantize(meta[relay.Constant][13] /* ty=Tensor[(128, 1, 1), float32] */, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(128, 1, 1), int8] */;
  %76 = qnn.add(%74, %75, 1f /* ty=float32 */, 0 /* ty=int32 */, 1f /* ty=float32 */, 0 /* ty=int32 */, 2f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(2, 128, 28, 28), int8] */;
  %77 = qnn.dequantize(%76, 2f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(2, 128, 28, 28), float32] */;
  %78 = qnn.quantize(%77, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(2, 128, 28, 28), int8] */;
  %79 = qnn.quantize(%58, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(2, 64, 56, 56), int8] */;
  %80 = nn.pad(%79, pad_width=[[0, 0], [0, 0], [0, 0], [0, 0]]) /* ty=Tensor[(2, 64, 56, 56), int8] */;
  %81 = qnn.quantize(meta[relay.Constant][14] /* ty=Tensor[(128, 64, 1, 1), float32] */, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(128, 64, 1, 1), int8] */;
  %82 = qnn.conv2d(%80, %81, 0 /* ty=int32 */, 0 /* ty=int32 */, 1f /* ty=float32 */, 1f /* ty=float32 */, strides=[2, 2], padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1], out_dtype="int32") /* ty=Tensor[(2, 128, 28, 28), int32] */;
  %83 = qnn.dequantize(%82, 1f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(2, 128, 28, 28), float32] */;
  %84 = qnn.quantize(%83, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(2, 128, 28, 28), int8] */;
  %85 = qnn.quantize(meta[relay.Constant][15] /* ty=Tensor[(128, 1, 1), float32] */, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(128, 1, 1), int8] */;
  %86 = qnn.add(%84, %85, 1f /* ty=float32 */, 0 /* ty=int32 */, 1f /* ty=float32 */, 0 /* ty=int32 */, 2f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(2, 128, 28, 28), int8] */;
  %87 = qnn.dequantize(%86, 2f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(2, 128, 28, 28), float32] */;
  %88 = qnn.quantize(%87, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(2, 128, 28, 28), int8] */;
  %89 = qnn.add(%78, %88, 1f /* ty=float32 */, 0 /* ty=int32 */, 1f /* ty=float32 */, 0 /* ty=int32 */, 2f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(2, 128, 28, 28), int8] */;
  %90 = qnn.dequantize(%89, 2f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(2, 128, 28, 28), float32] */;
  %91 = nn.relu(%90) /* ty=Tensor[(2, 128, 28, 28), float32] */;
  %92 = qnn.quantize(%91, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(2, 128, 28, 28), int8] */;
  %93 = nn.pad(%92, pad_width=[[0, 0], [0, 0], [1, 1], [1, 1]]) /* ty=Tensor[(2, 128, 30, 30), int8] */;
  %94 = qnn.quantize(meta[relay.Constant][16] /* ty=Tensor[(128, 128, 3, 3), float32] */, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(128, 128, 3, 3), int8] */;
  %95 = qnn.conv2d(%93, %94, 0 /* ty=int32 */, 0 /* ty=int32 */, 1f /* ty=float32 */, 1f /* ty=float32 */, padding=[0, 0, 0, 0], channels=128, kernel_size=[3, 3], out_dtype="int32") /* ty=Tensor[(2, 128, 28, 28), int32] */;
  %96 = qnn.dequantize(%95, 1f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(2, 128, 28, 28), float32] */;
  %97 = qnn.quantize(%96, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(2, 128, 28, 28), int8] */;
  %98 = qnn.quantize(meta[relay.Constant][17] /* ty=Tensor[(128, 1, 1), float32] */, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(128, 1, 1), int8] */;
  %99 = qnn.add(%97, %98, 1f /* ty=float32 */, 0 /* ty=int32 */, 1f /* ty=float32 */, 0 /* ty=int32 */, 2f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(2, 128, 28, 28), int8] */;
  %100 = qnn.dequantize(%99, 2f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(2, 128, 28, 28), float32] */;
  %101 = nn.relu(%100) /* ty=Tensor[(2, 128, 28, 28), float32] */;
  %102 = qnn.quantize(%101, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(2, 128, 28, 28), int8] */;
  %103 = nn.pad(%102, pad_width=[[0, 0], [0, 0], [1, 1], [1, 1]]) /* ty=Tensor[(2, 128, 30, 30), int8] */;
  %104 = qnn.quantize(meta[relay.Constant][18] /* ty=Tensor[(128, 128, 3, 3), float32] */, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(128, 128, 3, 3), int8] */;
  %105 = qnn.conv2d(%103, %104, 0 /* ty=int32 */, 0 /* ty=int32 */, 1f /* ty=float32 */, 1f /* ty=float32 */, padding=[0, 0, 0, 0], channels=128, kernel_size=[3, 3], out_dtype="int32") /* ty=Tensor[(2, 128, 28, 28), int32] */;
  %106 = qnn.dequantize(%105, 1f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(2, 128, 28, 28), float32] */;
  %107 = qnn.quantize(%106, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(2, 128, 28, 28), int8] */;
  %108 = qnn.quantize(meta[relay.Constant][19] /* ty=Tensor[(128, 1, 1), float32] */, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(128, 1, 1), int8] */;
  %109 = qnn.add(%107, %108, 1f /* ty=float32 */, 0 /* ty=int32 */, 1f /* ty=float32 */, 0 /* ty=int32 */, 2f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(2, 128, 28, 28), int8] */;
  %110 = qnn.dequantize(%109, 2f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(2, 128, 28, 28), float32] */;
  %111 = qnn.quantize(%110, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(2, 128, 28, 28), int8] */;
  %112 = qnn.quantize(%91, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(2, 128, 28, 28), int8] */;
  %113 = qnn.add(%111, %112, 1f /* ty=float32 */, 0 /* ty=int32 */, 1f /* ty=float32 */, 0 /* ty=int32 */, 2f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(2, 128, 28, 28), int8] */;
  %114 = qnn.dequantize(%113, 2f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(2, 128, 28, 28), float32] */;
  %115 = nn.relu(%114) /* ty=Tensor[(2, 128, 28, 28), float32] */;
  %116 = qnn.quantize(%115, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(2, 128, 28, 28), int8] */;
  %117 = nn.pad(%116, pad_width=[[0, 0], [0, 0], [1, 1], [1, 1]]) /* ty=Tensor[(2, 128, 30, 30), int8] */;
  %118 = qnn.quantize(meta[relay.Constant][20] /* ty=Tensor[(256, 128, 3, 3), float32] */, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(256, 128, 3, 3), int8] */;
  %119 = qnn.conv2d(%117, %118, 0 /* ty=int32 */, 0 /* ty=int32 */, 1f /* ty=float32 */, 1f /* ty=float32 */, strides=[2, 2], padding=[0, 0, 0, 0], channels=256, kernel_size=[3, 3], out_dtype="int32") /* ty=Tensor[(2, 256, 14, 14), int32] */;
  %120 = qnn.dequantize(%119, 1f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(2, 256, 14, 14), float32] */;
  %121 = qnn.quantize(%120, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(2, 256, 14, 14), int8] */;
  %122 = qnn.quantize(meta[relay.Constant][21] /* ty=Tensor[(256, 1, 1), float32] */, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(256, 1, 1), int8] */;
  %123 = qnn.add(%121, %122, 1f /* ty=float32 */, 0 /* ty=int32 */, 1f /* ty=float32 */, 0 /* ty=int32 */, 2f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(2, 256, 14, 14), int8] */;
  %124 = qnn.dequantize(%123, 2f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(2, 256, 14, 14), float32] */;
  %125 = nn.relu(%124) /* ty=Tensor[(2, 256, 14, 14), float32] */;
  %126 = qnn.quantize(%125, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(2, 256, 14, 14), int8] */;
  %127 = nn.pad(%126, pad_width=[[0, 0], [0, 0], [1, 1], [1, 1]]) /* ty=Tensor[(2, 256, 16, 16), int8] */;
  %128 = qnn.quantize(meta[relay.Constant][22] /* ty=Tensor[(256, 256, 3, 3), float32] */, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(256, 256, 3, 3), int8] */;
  %129 = qnn.conv2d(%127, %128, 0 /* ty=int32 */, 0 /* ty=int32 */, 1f /* ty=float32 */, 1f /* ty=float32 */, padding=[0, 0, 0, 0], channels=256, kernel_size=[3, 3], out_dtype="int32") /* ty=Tensor[(2, 256, 14, 14), int32] */;
  %130 = qnn.dequantize(%129, 1f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(2, 256, 14, 14), float32] */;
  %131 = qnn.quantize(%130, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(2, 256, 14, 14), int8] */;
  %132 = qnn.quantize(meta[relay.Constant][23] /* ty=Tensor[(256, 1, 1), float32] */, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(256, 1, 1), int8] */;
  %133 = qnn.add(%131, %132, 1f /* ty=float32 */, 0 /* ty=int32 */, 1f /* ty=float32 */, 0 /* ty=int32 */, 2f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(2, 256, 14, 14), int8] */;
  %134 = qnn.dequantize(%133, 2f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(2, 256, 14, 14), float32] */;
  %135 = qnn.quantize(%134, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(2, 256, 14, 14), int8] */;
  %136 = qnn.quantize(%115, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(2, 128, 28, 28), int8] */;
  %137 = nn.pad(%136, pad_width=[[0, 0], [0, 0], [0, 0], [0, 0]]) /* ty=Tensor[(2, 128, 28, 28), int8] */;
  %138 = qnn.quantize(meta[relay.Constant][24] /* ty=Tensor[(256, 128, 1, 1), float32] */, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(256, 128, 1, 1), int8] */;
  %139 = qnn.conv2d(%137, %138, 0 /* ty=int32 */, 0 /* ty=int32 */, 1f /* ty=float32 */, 1f /* ty=float32 */, strides=[2, 2], padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1], out_dtype="int32") /* ty=Tensor[(2, 256, 14, 14), int32] */;
  %140 = qnn.dequantize(%139, 1f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(2, 256, 14, 14), float32] */;
  %141 = qnn.quantize(%140, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(2, 256, 14, 14), int8] */;
  %142 = qnn.quantize(meta[relay.Constant][25] /* ty=Tensor[(256, 1, 1), float32] */, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(256, 1, 1), int8] */;
  %143 = qnn.add(%141, %142, 1f /* ty=float32 */, 0 /* ty=int32 */, 1f /* ty=float32 */, 0 /* ty=int32 */, 2f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(2, 256, 14, 14), int8] */;
  %144 = qnn.dequantize(%143, 2f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(2, 256, 14, 14), float32] */;
  %145 = qnn.quantize(%144, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(2, 256, 14, 14), int8] */;
  %146 = qnn.add(%135, %145, 1f /* ty=float32 */, 0 /* ty=int32 */, 1f /* ty=float32 */, 0 /* ty=int32 */, 2f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(2, 256, 14, 14), int8] */;
  %147 = qnn.dequantize(%146, 2f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(2, 256, 14, 14), float32] */;
  %148 = nn.relu(%147) /* ty=Tensor[(2, 256, 14, 14), float32] */;
  %149 = qnn.quantize(%148, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(2, 256, 14, 14), int8] */;
  %150 = nn.pad(%149, pad_width=[[0, 0], [0, 0], [1, 1], [1, 1]]) /* ty=Tensor[(2, 256, 16, 16), int8] */;
  %151 = qnn.quantize(meta[relay.Constant][26] /* ty=Tensor[(256, 256, 3, 3), float32] */, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(256, 256, 3, 3), int8] */;
  %152 = qnn.conv2d(%150, %151, 0 /* ty=int32 */, 0 /* ty=int32 */, 1f /* ty=float32 */, 1f /* ty=float32 */, padding=[0, 0, 0, 0], channels=256, kernel_size=[3, 3], out_dtype="int32") /* ty=Tensor[(2, 256, 14, 14), int32] */;
  %153 = qnn.dequantize(%152, 1f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(2, 256, 14, 14), float32] */;
  %154 = qnn.quantize(%153, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(2, 256, 14, 14), int8] */;
  %155 = qnn.quantize(meta[relay.Constant][27] /* ty=Tensor[(256, 1, 1), float32] */, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(256, 1, 1), int8] */;
  %156 = qnn.add(%154, %155, 1f /* ty=float32 */, 0 /* ty=int32 */, 1f /* ty=float32 */, 0 /* ty=int32 */, 2f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(2, 256, 14, 14), int8] */;
  %157 = qnn.dequantize(%156, 2f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(2, 256, 14, 14), float32] */;
  %158 = nn.relu(%157) /* ty=Tensor[(2, 256, 14, 14), float32] */;
  %159 = qnn.quantize(%158, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(2, 256, 14, 14), int8] */;
  %160 = nn.pad(%159, pad_width=[[0, 0], [0, 0], [1, 1], [1, 1]]) /* ty=Tensor[(2, 256, 16, 16), int8] */;
  %161 = qnn.quantize(meta[relay.Constant][28] /* ty=Tensor[(256, 256, 3, 3), float32] */, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(256, 256, 3, 3), int8] */;
  %162 = qnn.conv2d(%160, %161, 0 /* ty=int32 */, 0 /* ty=int32 */, 1f /* ty=float32 */, 1f /* ty=float32 */, padding=[0, 0, 0, 0], channels=256, kernel_size=[3, 3], out_dtype="int32") /* ty=Tensor[(2, 256, 14, 14), int32] */;
  %163 = qnn.dequantize(%162, 1f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(2, 256, 14, 14), float32] */;
  %164 = qnn.quantize(%163, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(2, 256, 14, 14), int8] */;
  %165 = qnn.quantize(meta[relay.Constant][29] /* ty=Tensor[(256, 1, 1), float32] */, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(256, 1, 1), int8] */;
  %166 = qnn.add(%164, %165, 1f /* ty=float32 */, 0 /* ty=int32 */, 1f /* ty=float32 */, 0 /* ty=int32 */, 2f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(2, 256, 14, 14), int8] */;
  %167 = qnn.dequantize(%166, 2f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(2, 256, 14, 14), float32] */;
  %168 = qnn.quantize(%167, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(2, 256, 14, 14), int8] */;
  %169 = qnn.quantize(%148, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(2, 256, 14, 14), int8] */;
  %170 = qnn.add(%168, %169, 1f /* ty=float32 */, 0 /* ty=int32 */, 1f /* ty=float32 */, 0 /* ty=int32 */, 2f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(2, 256, 14, 14), int8] */;
  %171 = qnn.dequantize(%170, 2f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(2, 256, 14, 14), float32] */;
  %172 = nn.relu(%171) /* ty=Tensor[(2, 256, 14, 14), float32] */;
  %173 = qnn.quantize(%172, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(2, 256, 14, 14), int8] */;
  %174 = nn.pad(%173, pad_width=[[0, 0], [0, 0], [1, 1], [1, 1]]) /* ty=Tensor[(2, 256, 16, 16), int8] */;
  %175 = qnn.quantize(meta[relay.Constant][30] /* ty=Tensor[(512, 256, 3, 3), float32] */, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(512, 256, 3, 3), int8] */;
  %176 = qnn.conv2d(%174, %175, 0 /* ty=int32 */, 0 /* ty=int32 */, 1f /* ty=float32 */, 1f /* ty=float32 */, strides=[2, 2], padding=[0, 0, 0, 0], channels=512, kernel_size=[3, 3], out_dtype="int32") /* ty=Tensor[(2, 512, 7, 7), int32] */;
  %177 = qnn.dequantize(%176, 1f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(2, 512, 7, 7), float32] */;
  %178 = qnn.quantize(%177, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(2, 512, 7, 7), int8] */;
  %179 = qnn.quantize(meta[relay.Constant][31] /* ty=Tensor[(512, 1, 1), float32] */, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(512, 1, 1), int8] */;
  %180 = qnn.add(%178, %179, 1f /* ty=float32 */, 0 /* ty=int32 */, 1f /* ty=float32 */, 0 /* ty=int32 */, 2f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(2, 512, 7, 7), int8] */;
  %181 = qnn.dequantize(%180, 2f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(2, 512, 7, 7), float32] */;
  %182 = nn.relu(%181) /* ty=Tensor[(2, 512, 7, 7), float32] */;
  %183 = qnn.quantize(%182, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(2, 512, 7, 7), int8] */;
  %184 = nn.pad(%183, pad_width=[[0, 0], [0, 0], [1, 1], [1, 1]]) /* ty=Tensor[(2, 512, 9, 9), int8] */;
  %185 = qnn.quantize(meta[relay.Constant][32] /* ty=Tensor[(512, 512, 3, 3), float32] */, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(512, 512, 3, 3), int8] */;
  %186 = qnn.conv2d(%184, %185, 0 /* ty=int32 */, 0 /* ty=int32 */, 1f /* ty=float32 */, 1f /* ty=float32 */, padding=[0, 0, 0, 0], channels=512, kernel_size=[3, 3], out_dtype="int32") /* ty=Tensor[(2, 512, 7, 7), int32] */;
  %187 = qnn.dequantize(%186, 1f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(2, 512, 7, 7), float32] */;
  %188 = qnn.quantize(%187, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(2, 512, 7, 7), int8] */;
  %189 = qnn.quantize(meta[relay.Constant][33] /* ty=Tensor[(512, 1, 1), float32] */, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(512, 1, 1), int8] */;
  %190 = qnn.add(%188, %189, 1f /* ty=float32 */, 0 /* ty=int32 */, 1f /* ty=float32 */, 0 /* ty=int32 */, 2f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(2, 512, 7, 7), int8] */;
  %191 = qnn.dequantize(%190, 2f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(2, 512, 7, 7), float32] */;
  %192 = qnn.quantize(%191, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(2, 512, 7, 7), int8] */;
  %193 = qnn.quantize(%172, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(2, 256, 14, 14), int8] */;
  %194 = nn.pad(%193, pad_width=[[0, 0], [0, 0], [0, 0], [0, 0]]) /* ty=Tensor[(2, 256, 14, 14), int8] */;
  %195 = qnn.quantize(meta[relay.Constant][34] /* ty=Tensor[(512, 256, 1, 1), float32] */, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(512, 256, 1, 1), int8] */;
  %196 = qnn.conv2d(%194, %195, 0 /* ty=int32 */, 0 /* ty=int32 */, 1f /* ty=float32 */, 1f /* ty=float32 */, strides=[2, 2], padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1], out_dtype="int32") /* ty=Tensor[(2, 512, 7, 7), int32] */;
  %197 = qnn.dequantize(%196, 1f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(2, 512, 7, 7), float32] */;
  %198 = qnn.quantize(%197, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(2, 512, 7, 7), int8] */;
  %199 = qnn.quantize(meta[relay.Constant][35] /* ty=Tensor[(512, 1, 1), float32] */, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(512, 1, 1), int8] */;
  %200 = qnn.add(%198, %199, 1f /* ty=float32 */, 0 /* ty=int32 */, 1f /* ty=float32 */, 0 /* ty=int32 */, 2f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(2, 512, 7, 7), int8] */;
  %201 = qnn.dequantize(%200, 2f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(2, 512, 7, 7), float32] */;
  %202 = qnn.quantize(%201, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(2, 512, 7, 7), int8] */;
  %203 = qnn.add(%192, %202, 1f /* ty=float32 */, 0 /* ty=int32 */, 1f /* ty=float32 */, 0 /* ty=int32 */, 2f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(2, 512, 7, 7), int8] */;
  %204 = qnn.dequantize(%203, 2f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(2, 512, 7, 7), float32] */;
  %205 = nn.relu(%204) /* ty=Tensor[(2, 512, 7, 7), float32] */;
  %206 = qnn.quantize(%205, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(2, 512, 7, 7), int8] */;
  %207 = nn.pad(%206, pad_width=[[0, 0], [0, 0], [1, 1], [1, 1]]) /* ty=Tensor[(2, 512, 9, 9), int8] */;
  %208 = qnn.quantize(meta[relay.Constant][36] /* ty=Tensor[(512, 512, 3, 3), float32] */, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(512, 512, 3, 3), int8] */;
  %209 = qnn.conv2d(%207, %208, 0 /* ty=int32 */, 0 /* ty=int32 */, 1f /* ty=float32 */, 1f /* ty=float32 */, padding=[0, 0, 0, 0], channels=512, kernel_size=[3, 3], out_dtype="int32") /* ty=Tensor[(2, 512, 7, 7), int32] */;
  %210 = qnn.dequantize(%209, 1f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(2, 512, 7, 7), float32] */;
  %211 = qnn.quantize(%210, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(2, 512, 7, 7), int8] */;
  %212 = qnn.quantize(meta[relay.Constant][37] /* ty=Tensor[(512, 1, 1), float32] */, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(512, 1, 1), int8] */;
  %213 = qnn.add(%211, %212, 1f /* ty=float32 */, 0 /* ty=int32 */, 1f /* ty=float32 */, 0 /* ty=int32 */, 2f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(2, 512, 7, 7), int8] */;
  %214 = qnn.dequantize(%213, 2f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(2, 512, 7, 7), float32] */;
  %215 = nn.relu(%214) /* ty=Tensor[(2, 512, 7, 7), float32] */;
  %216 = qnn.quantize(%215, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(2, 512, 7, 7), int8] */;
  %217 = nn.pad(%216, pad_width=[[0, 0], [0, 0], [1, 1], [1, 1]]) /* ty=Tensor[(2, 512, 9, 9), int8] */;
  %218 = qnn.quantize(meta[relay.Constant][38] /* ty=Tensor[(512, 512, 3, 3), float32] */, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(512, 512, 3, 3), int8] */;
  %219 = qnn.conv2d(%217, %218, 0 /* ty=int32 */, 0 /* ty=int32 */, 1f /* ty=float32 */, 1f /* ty=float32 */, padding=[0, 0, 0, 0], channels=512, kernel_size=[3, 3], out_dtype="int32") /* ty=Tensor[(2, 512, 7, 7), int32] */;
  %220 = qnn.dequantize(%219, 1f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(2, 512, 7, 7), float32] */;
  %221 = qnn.quantize(%220, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(2, 512, 7, 7), int8] */;
  %222 = qnn.quantize(meta[relay.Constant][39] /* ty=Tensor[(512, 1, 1), float32] */, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(512, 1, 1), int8] */;
  %223 = qnn.add(%221, %222, 1f /* ty=float32 */, 0 /* ty=int32 */, 1f /* ty=float32 */, 0 /* ty=int32 */, 2f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(2, 512, 7, 7), int8] */;
  %224 = qnn.dequantize(%223, 2f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(2, 512, 7, 7), float32] */;
  %225 = qnn.quantize(%224, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(2, 512, 7, 7), int8] */;
  %226 = qnn.quantize(%205, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(2, 512, 7, 7), int8] */;
  %227 = qnn.add(%225, %226, 1f /* ty=float32 */, 0 /* ty=int32 */, 1f /* ty=float32 */, 0 /* ty=int32 */, 2f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(2, 512, 7, 7), int8] */;
  %228 = qnn.dequantize(%227, 2f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(2, 512, 7, 7), float32] */;
  %229 = nn.relu(%228) /* ty=Tensor[(2, 512, 7, 7), float32] */;
  %230 = nn.adaptive_avg_pool2d(%229, output_size=[1, 1]) /* ty=Tensor[(2, 512, 1, 1), float32] */;
  %231 = reshape(%230, newshape=[0, -1, 1, 1]) /* ty=Tensor[(2, 512, 1, 1), float32] */;
  %232 = squeeze(%231, axis=[2, 3]) /* ty=Tensor[(2, 512), float32] */;
  %233 = qnn.quantize(%232, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(2, 512), int8] */;
  %234 = qnn.quantize(meta[relay.Constant][40] /* ty=Tensor[(1000, 512), float32] */, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(1000, 512), int8] */;
  %235 = qnn.dense(%233, %234, 0 /* ty=int32 */, 0 /* ty=int32 */, 1f /* ty=float32 */, 1f /* ty=float32 */, units=1000, out_dtype="int32") /* ty=Tensor[(2, 1000), int32] */;
  %236 = qnn.dequantize(%235, 1f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(2, 1000), float32] */;
  %237 = qnn.quantize(%236, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(2, 1000), int8] */;
  %238 = qnn.quantize(meta[relay.Constant][41] /* ty=Tensor[(1000), float32] */, 1f /* ty=float32 */, 0 /* ty=int32 */, out_dtype="int8") /* ty=Tensor[(1000), int8] */;
  %239 = qnn.add(%237, %238, 1f /* ty=float32 */, 0 /* ty=int32 */, 1f /* ty=float32 */, 0 /* ty=int32 */, 2f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(2, 1000), int8] */;
  qnn.dequantize(%239, 2f /* ty=float32 */, 0 /* ty=int32 */) /* ty=Tensor[(2, 1000), float32] */
}

/* For debugging purposes the metadata section has been omitted.
 * If you would like to see the full metadata section you can set the 
 * option to `True` when invoking `astext`. 
 */
