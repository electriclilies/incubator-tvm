fn (%input: Tensor[(1, 3, 224, 224), float32], %conv2d_data_scale_0, %conv2d_weight_scale_1, %add_lhs_scale_2, %add_rhs_scale_3, %add_out_scale_4, %conv2d_data_scale_5, %conv2d_weight_scale_6, %add_lhs_scale_7, %add_rhs_scale_8, %add_out_scale_9, %conv2d_data_scale_10, %conv2d_weight_scale_11, %add_lhs_scale_12, %add_rhs_scale_13, %add_out_scale_14, %add_lhs_scale_15, %add_rhs_scale_16, %add_out_scale_17, %conv2d_data_scale_18, %conv2d_weight_scale_19, %add_lhs_scale_20, %add_rhs_scale_21, %add_out_scale_22, %conv2d_data_scale_23, %conv2d_weight_scale_24, %add_lhs_scale_25, %add_rhs_scale_26, %add_out_scale_27, %add_lhs_scale_28, %add_rhs_scale_29, %add_out_scale_30, %conv2d_data_scale_31, %conv2d_weight_scale_32, %add_lhs_scale_33, %add_rhs_scale_34, %add_out_scale_35, %conv2d_data_scale_36, %conv2d_weight_scale_37, %add_lhs_scale_38, %add_rhs_scale_39, %add_out_scale_40, %conv2d_data_scale_41, %conv2d_weight_scale_42, %add_lhs_scale_43, %add_rhs_scale_44, %add_out_scale_45, %add_lhs_scale_46, %add_rhs_scale_47, %add_out_scale_48, %conv2d_data_scale_49, %conv2d_weight_scale_50, %add_lhs_scale_51, %add_rhs_scale_52, %add_out_scale_53, %conv2d_data_scale_54, %conv2d_weight_scale_55, %add_lhs_scale_56, %add_rhs_scale_57, %add_out_scale_58, %add_lhs_scale_59, %add_rhs_scale_60, %add_out_scale_61, %conv2d_data_scale_62, %conv2d_weight_scale_63, %add_lhs_scale_64, %add_rhs_scale_65, %add_out_scale_66, %conv2d_data_scale_67, %conv2d_weight_scale_68, %add_lhs_scale_69, %add_rhs_scale_70, %add_out_scale_71, %conv2d_data_scale_72, %conv2d_weight_scale_73, %add_lhs_scale_74, %add_rhs_scale_75, %add_out_scale_76, %add_lhs_scale_77, %add_rhs_scale_78, %add_out_scale_79, %conv2d_data_scale_80, %conv2d_weight_scale_81, %add_lhs_scale_82, %add_rhs_scale_83, %add_out_scale_84, %conv2d_data_scale_85, %conv2d_weight_scale_86, %add_lhs_scale_87, %add_rhs_scale_88, %add_out_scale_89, %add_lhs_scale_90, %add_rhs_scale_91, %add_out_scale_92, %conv2d_data_scale_93, %conv2d_weight_scale_94, %add_lhs_scale_95, %add_rhs_scale_96, %add_out_scale_97, %conv2d_data_scale_98, %conv2d_weight_scale_99, %add_lhs_scale_100, %add_rhs_scale_101, %add_out_scale_102, %conv2d_data_scale_103, %conv2d_weight_scale_104, %add_lhs_scale_105, %add_rhs_scale_106, %add_out_scale_107, %add_lhs_scale_108, %add_rhs_scale_109, %add_out_scale_110, %conv2d_data_scale_111, %conv2d_weight_scale_112, %add_lhs_scale_113, %add_rhs_scale_114, %add_out_scale_115, %conv2d_data_scale_116, %conv2d_weight_scale_117, %add_lhs_scale_118, %add_rhs_scale_119, %add_out_scale_120, %add_lhs_scale_121, %add_rhs_scale_122, %add_out_scale_123, %dense_data_scale_124, %dense_weight_scale_125, %add_lhs_scale_126, %add_rhs_scale_127, %add_out_scale_128, %conv2d_data_zero_pt_0, %conv2d_weight_zero_pt_1, %add_lhs_zero_pt_2, %add_rhs_zero_pt_3, %add_out_zero_pt_4, %conv2d_data_zero_pt_5, %conv2d_weight_zero_pt_6, %add_lhs_zero_pt_7, %add_rhs_zero_pt_8, %add_out_zero_pt_9, %conv2d_data_zero_pt_10, %conv2d_weight_zero_pt_11, %add_lhs_zero_pt_12, %add_rhs_zero_pt_13, %add_out_zero_pt_14, %add_lhs_zero_pt_15, %add_rhs_zero_pt_16, %add_out_zero_pt_17, %conv2d_data_zero_pt_18, %conv2d_weight_zero_pt_19, %add_lhs_zero_pt_20, %add_rhs_zero_pt_21, %add_out_zero_pt_22, %conv2d_data_zero_pt_23, %conv2d_weight_zero_pt_24, %add_lhs_zero_pt_25, %add_rhs_zero_pt_26, %add_out_zero_pt_27, %add_lhs_zero_pt_28, %add_rhs_zero_pt_29, %add_out_zero_pt_30, %conv2d_data_zero_pt_31, %conv2d_weight_zero_pt_32, %add_lhs_zero_pt_33, %add_rhs_zero_pt_34, %add_out_zero_pt_35, %conv2d_data_zero_pt_36, %conv2d_weight_zero_pt_37, %add_lhs_zero_pt_38, %add_rhs_zero_pt_39, %add_out_zero_pt_40, %conv2d_data_zero_pt_41, %conv2d_weight_zero_pt_42, %add_lhs_zero_pt_43, %add_rhs_zero_pt_44, %add_out_zero_pt_45, %add_lhs_zero_pt_46, %add_rhs_zero_pt_47, %add_out_zero_pt_48, %conv2d_data_zero_pt_49, %conv2d_weight_zero_pt_50, %add_lhs_zero_pt_51, %add_rhs_zero_pt_52, %add_out_zero_pt_53, %conv2d_data_zero_pt_54, %conv2d_weight_zero_pt_55, %add_lhs_zero_pt_56, %add_rhs_zero_pt_57, %add_out_zero_pt_58, %add_lhs_zero_pt_59, %add_rhs_zero_pt_60, %add_out_zero_pt_61, %conv2d_data_zero_pt_62, %conv2d_weight_zero_pt_63, %add_lhs_zero_pt_64, %add_rhs_zero_pt_65, %add_out_zero_pt_66, %conv2d_data_zero_pt_67, %conv2d_weight_zero_pt_68, %add_lhs_zero_pt_69, %add_rhs_zero_pt_70, %add_out_zero_pt_71, %conv2d_data_zero_pt_72, %conv2d_weight_zero_pt_73, %add_lhs_zero_pt_74, %add_rhs_zero_pt_75, %add_out_zero_pt_76, %add_lhs_zero_pt_77, %add_rhs_zero_pt_78, %add_out_zero_pt_79, %conv2d_data_zero_pt_80, %conv2d_weight_zero_pt_81, %add_lhs_zero_pt_82, %add_rhs_zero_pt_83, %add_out_zero_pt_84, %conv2d_data_zero_pt_85, %conv2d_weight_zero_pt_86, %add_lhs_zero_pt_87, %add_rhs_zero_pt_88, %add_out_zero_pt_89, %add_lhs_zero_pt_90, %add_rhs_zero_pt_91, %add_out_zero_pt_92, %conv2d_data_zero_pt_93, %conv2d_weight_zero_pt_94, %add_lhs_zero_pt_95, %add_rhs_zero_pt_96, %add_out_zero_pt_97, %conv2d_data_zero_pt_98, %conv2d_weight_zero_pt_99, %add_lhs_zero_pt_100, %add_rhs_zero_pt_101, %add_out_zero_pt_102, %conv2d_data_zero_pt_103, %conv2d_weight_zero_pt_104, %add_lhs_zero_pt_105, %add_rhs_zero_pt_106, %add_out_zero_pt_107, %add_lhs_zero_pt_108, %add_rhs_zero_pt_109, %add_out_zero_pt_110, %conv2d_data_zero_pt_111, %conv2d_weight_zero_pt_112, %add_lhs_zero_pt_113, %add_rhs_zero_pt_114, %add_out_zero_pt_115, %conv2d_data_zero_pt_116, %conv2d_weight_zero_pt_117, %add_lhs_zero_pt_118, %add_rhs_zero_pt_119, %add_out_zero_pt_120, %add_lhs_zero_pt_121, %add_rhs_zero_pt_122, %add_out_zero_pt_123, %dense_data_zero_pt_124, %dense_weight_zero_pt_125, %add_lhs_zero_pt_126, %add_rhs_zero_pt_127, %add_out_zero_pt_128) {
  %0 = qnn.quantize(%input, %conv2d_data_scale_0, %conv2d_data_zero_pt_0, out_dtype="int8");
  %1 = nn.pad(%0, pad_width=[[0, 0], [0, 0], [3, 3], [3, 3]]);
  %2 = qnn.quantize(meta[relay.Constant][0] /* ty=Tensor[(64, 3, 7, 7), float32] */ /* ty=Tensor[(64, 3, 7, 7), float32] */, %conv2d_weight_scale_1, %conv2d_weight_zero_pt_1, out_dtype="int8");
  %3 = qnn.conv2d(%1, %2, %conv2d_data_zero_pt_0, %conv2d_weight_zero_pt_1, %conv2d_data_scale_0, %conv2d_weight_scale_1, strides=[2, 2], padding=[0, 0, 0, 0], channels=64, kernel_size=[7, 7], out_dtype="int32");
  %4 = multiply(%conv2d_data_scale_0, %conv2d_weight_scale_1);
  %5 = qnn.dequantize(%3, %4, 0);
  %6 = qnn.quantize(%5, %add_lhs_scale_2, %add_lhs_zero_pt_2, out_dtype="int8");
  %7 = qnn.quantize(meta[relay.Constant][1] /* ty=Tensor[(64, 1, 1), float32] */ /* ty=Tensor[(64, 1, 1), float32] */, %add_rhs_scale_3, %add_rhs_zero_pt_3, out_dtype="int8");
  %8 = qnn.add(%6, %7, %add_lhs_scale_2, %add_lhs_zero_pt_2, %add_rhs_scale_3, %add_rhs_zero_pt_3, %add_out_scale_4, %add_out_zero_pt_4);
  %9 = qnn.dequantize(%8, %add_out_scale_4, %add_out_zero_pt_4);
  %10 = nn.relu(%9);
  %11 = nn.max_pool2d(%10, pool_size=[3, 3], strides=[2, 2], padding=[1, 1, 1, 1]);
  %12 = qnn.quantize(%11, %conv2d_data_scale_5, %conv2d_data_zero_pt_5, out_dtype="int8");
  %13 = nn.pad(%12, pad_width=[[0, 0], [0, 0], [1, 1], [1, 1]]);
  %14 = qnn.quantize(meta[relay.Constant][2] /* ty=Tensor[(64, 64, 3, 3), float32] */ /* ty=Tensor[(64, 64, 3, 3), float32] */, %conv2d_weight_scale_6, %conv2d_weight_zero_pt_6, out_dtype="int8");
  %15 = qnn.conv2d(%13, %14, %conv2d_data_zero_pt_5, %conv2d_weight_zero_pt_6, %conv2d_data_scale_5, %conv2d_weight_scale_6, padding=[0, 0, 0, 0], channels=64, kernel_size=[3, 3], out_dtype="int32");
  %16 = multiply(%conv2d_data_scale_5, %conv2d_weight_scale_6);
  %17 = qnn.dequantize(%15, %16, 0);
  %18 = qnn.quantize(%17, %add_lhs_scale_7, %add_lhs_zero_pt_7, out_dtype="int8");
  %19 = qnn.quantize(meta[relay.Constant][3] /* ty=Tensor[(64, 1, 1), float32] */ /* ty=Tensor[(64, 1, 1), float32] */, %add_rhs_scale_8, %add_rhs_zero_pt_8, out_dtype="int8");
  %20 = qnn.add(%18, %19, %add_lhs_scale_7, %add_lhs_zero_pt_7, %add_rhs_scale_8, %add_rhs_zero_pt_8, %add_out_scale_9, %add_out_zero_pt_9);
  %21 = qnn.dequantize(%20, %add_out_scale_9, %add_out_zero_pt_9);
  %22 = nn.relu(%21);
  %23 = qnn.quantize(%22, %conv2d_data_scale_10, %conv2d_data_zero_pt_10, out_dtype="int8");
  %24 = nn.pad(%23, pad_width=[[0, 0], [0, 0], [1, 1], [1, 1]]);
  %25 = qnn.quantize(meta[relay.Constant][4] /* ty=Tensor[(64, 64, 3, 3), float32] */ /* ty=Tensor[(64, 64, 3, 3), float32] */, %conv2d_weight_scale_11, %conv2d_weight_zero_pt_11, out_dtype="int8");
  %26 = qnn.conv2d(%24, %25, %conv2d_data_zero_pt_10, %conv2d_weight_zero_pt_11, %conv2d_data_scale_10, %conv2d_weight_scale_11, padding=[0, 0, 0, 0], channels=64, kernel_size=[3, 3], out_dtype="int32");
  %27 = multiply(%conv2d_data_scale_10, %conv2d_weight_scale_11);
  %28 = qnn.dequantize(%26, %27, 0);
  %29 = qnn.quantize(%28, %add_lhs_scale_12, %add_lhs_zero_pt_12, out_dtype="int8");
  %30 = qnn.quantize(meta[relay.Constant][5] /* ty=Tensor[(64, 1, 1), float32] */ /* ty=Tensor[(64, 1, 1), float32] */, %add_rhs_scale_13, %add_rhs_zero_pt_13, out_dtype="int8");
  %31 = qnn.add(%29, %30, %add_lhs_scale_12, %add_lhs_zero_pt_12, %add_rhs_scale_13, %add_rhs_zero_pt_13, %add_out_scale_14, %add_out_zero_pt_14);
  %32 = qnn.dequantize(%31, %add_out_scale_14, %add_out_zero_pt_14);
  %33 = qnn.quantize(%32, %add_lhs_scale_15, %add_lhs_zero_pt_15, out_dtype="int8");
  %34 = qnn.quantize(%11, %add_rhs_scale_16, %add_rhs_zero_pt_16, out_dtype="int8");
  %35 = qnn.add(%33, %34, %add_lhs_scale_15, %add_lhs_zero_pt_15, %add_rhs_scale_16, %add_rhs_zero_pt_16, %add_out_scale_17, %add_out_zero_pt_17);
  %36 = qnn.dequantize(%35, %add_out_scale_17, %add_out_zero_pt_17);
  %37 = nn.relu(%36);
  %38 = qnn.quantize(%37, %conv2d_data_scale_18, %conv2d_data_zero_pt_18, out_dtype="int8");
  %39 = nn.pad(%38, pad_width=[[0, 0], [0, 0], [1, 1], [1, 1]]);
  %40 = qnn.quantize(meta[relay.Constant][6] /* ty=Tensor[(64, 64, 3, 3), float32] */ /* ty=Tensor[(64, 64, 3, 3), float32] */, %conv2d_weight_scale_19, %conv2d_weight_zero_pt_19, out_dtype="int8");
  %41 = qnn.conv2d(%39, %40, %conv2d_data_zero_pt_18, %conv2d_weight_zero_pt_19, %conv2d_data_scale_18, %conv2d_weight_scale_19, padding=[0, 0, 0, 0], channels=64, kernel_size=[3, 3], out_dtype="int32");
  %42 = multiply(%conv2d_data_scale_18, %conv2d_weight_scale_19);
  %43 = qnn.dequantize(%41, %42, 0);
  %44 = qnn.quantize(%43, %add_lhs_scale_20, %add_lhs_zero_pt_20, out_dtype="int8");
  %45 = qnn.quantize(meta[relay.Constant][7] /* ty=Tensor[(64, 1, 1), float32] */ /* ty=Tensor[(64, 1, 1), float32] */, %add_rhs_scale_21, %add_rhs_zero_pt_21, out_dtype="int8");
  %46 = qnn.add(%44, %45, %add_lhs_scale_20, %add_lhs_zero_pt_20, %add_rhs_scale_21, %add_rhs_zero_pt_21, %add_out_scale_22, %add_out_zero_pt_22);
  %47 = qnn.dequantize(%46, %add_out_scale_22, %add_out_zero_pt_22);
  %48 = nn.relu(%47);
  %49 = qnn.quantize(%48, %conv2d_data_scale_23, %conv2d_data_zero_pt_23, out_dtype="int8");
  %50 = nn.pad(%49, pad_width=[[0, 0], [0, 0], [1, 1], [1, 1]]);
  %51 = qnn.quantize(meta[relay.Constant][8] /* ty=Tensor[(64, 64, 3, 3), float32] */ /* ty=Tensor[(64, 64, 3, 3), float32] */, %conv2d_weight_scale_24, %conv2d_weight_zero_pt_24, out_dtype="int8");
  %52 = qnn.conv2d(%50, %51, %conv2d_data_zero_pt_23, %conv2d_weight_zero_pt_24, %conv2d_data_scale_23, %conv2d_weight_scale_24, padding=[0, 0, 0, 0], channels=64, kernel_size=[3, 3], out_dtype="int32");
  %53 = multiply(%conv2d_data_scale_23, %conv2d_weight_scale_24);
  %54 = qnn.dequantize(%52, %53, 0);
  %55 = qnn.quantize(%54, %add_lhs_scale_25, %add_lhs_zero_pt_25, out_dtype="int8");
  %56 = qnn.quantize(meta[relay.Constant][9] /* ty=Tensor[(64, 1, 1), float32] */ /* ty=Tensor[(64, 1, 1), float32] */, %add_rhs_scale_26, %add_rhs_zero_pt_26, out_dtype="int8");
  %57 = qnn.add(%55, %56, %add_lhs_scale_25, %add_lhs_zero_pt_25, %add_rhs_scale_26, %add_rhs_zero_pt_26, %add_out_scale_27, %add_out_zero_pt_27);
  %58 = qnn.dequantize(%57, %add_out_scale_27, %add_out_zero_pt_27);
  %59 = qnn.quantize(%58, %add_lhs_scale_28, %add_lhs_zero_pt_28, out_dtype="int8");
  %60 = qnn.quantize(%37, %add_rhs_scale_29, %add_rhs_zero_pt_29, out_dtype="int8");
  %61 = qnn.add(%59, %60, %add_lhs_scale_28, %add_lhs_zero_pt_28, %add_rhs_scale_29, %add_rhs_zero_pt_29, %add_out_scale_30, %add_out_zero_pt_30);
  %62 = qnn.dequantize(%61, %add_out_scale_30, %add_out_zero_pt_30);
  %63 = nn.relu(%62);
  %64 = qnn.quantize(%63, %conv2d_data_scale_31, %conv2d_data_zero_pt_31, out_dtype="int8");
  %65 = nn.pad(%64, pad_width=[[0, 0], [0, 0], [1, 1], [1, 1]]);
  %66 = qnn.quantize(meta[relay.Constant][10] /* ty=Tensor[(128, 64, 3, 3), float32] */ /* ty=Tensor[(128, 64, 3, 3), float32] */, %conv2d_weight_scale_32, %conv2d_weight_zero_pt_32, out_dtype="int8");
  %67 = qnn.conv2d(%65, %66, %conv2d_data_zero_pt_31, %conv2d_weight_zero_pt_32, %conv2d_data_scale_31, %conv2d_weight_scale_32, strides=[2, 2], padding=[0, 0, 0, 0], channels=128, kernel_size=[3, 3], out_dtype="int32");
  %68 = multiply(%conv2d_data_scale_31, %conv2d_weight_scale_32);
  %69 = qnn.dequantize(%67, %68, 0);
  %70 = qnn.quantize(%69, %add_lhs_scale_33, %add_lhs_zero_pt_33, out_dtype="int8");
  %71 = qnn.quantize(meta[relay.Constant][11] /* ty=Tensor[(128, 1, 1), float32] */ /* ty=Tensor[(128, 1, 1), float32] */, %add_rhs_scale_34, %add_rhs_zero_pt_34, out_dtype="int8");
  %72 = qnn.add(%70, %71, %add_lhs_scale_33, %add_lhs_zero_pt_33, %add_rhs_scale_34, %add_rhs_zero_pt_34, %add_out_scale_35, %add_out_zero_pt_35);
  %73 = qnn.dequantize(%72, %add_out_scale_35, %add_out_zero_pt_35);
  %74 = nn.relu(%73);
  %75 = qnn.quantize(%74, %conv2d_data_scale_36, %conv2d_data_zero_pt_36, out_dtype="int8");
  %76 = nn.pad(%75, pad_width=[[0, 0], [0, 0], [1, 1], [1, 1]]);
  %77 = qnn.quantize(meta[relay.Constant][12] /* ty=Tensor[(128, 128, 3, 3), float32] */ /* ty=Tensor[(128, 128, 3, 3), float32] */, %conv2d_weight_scale_37, %conv2d_weight_zero_pt_37, out_dtype="int8");
  %78 = qnn.conv2d(%76, %77, %conv2d_data_zero_pt_36, %conv2d_weight_zero_pt_37, %conv2d_data_scale_36, %conv2d_weight_scale_37, padding=[0, 0, 0, 0], channels=128, kernel_size=[3, 3], out_dtype="int32");
  %79 = multiply(%conv2d_data_scale_36, %conv2d_weight_scale_37);
  %80 = qnn.dequantize(%78, %79, 0);
  %81 = qnn.quantize(%80, %add_lhs_scale_38, %add_lhs_zero_pt_38, out_dtype="int8");
  %82 = qnn.quantize(meta[relay.Constant][13] /* ty=Tensor[(128, 1, 1), float32] */ /* ty=Tensor[(128, 1, 1), float32] */, %add_rhs_scale_39, %add_rhs_zero_pt_39, out_dtype="int8");
  %83 = qnn.add(%81, %82, %add_lhs_scale_38, %add_lhs_zero_pt_38, %add_rhs_scale_39, %add_rhs_zero_pt_39, %add_out_scale_40, %add_out_zero_pt_40);
  %84 = qnn.dequantize(%83, %add_out_scale_40, %add_out_zero_pt_40);
  %85 = qnn.quantize(%84, %add_lhs_scale_46, %add_lhs_zero_pt_46, out_dtype="int8");
  %86 = qnn.quantize(%63, %conv2d_data_scale_41, %conv2d_data_zero_pt_41, out_dtype="int8");
  %87 = nn.pad(%86, pad_width=[[0, 0], [0, 0], [0, 0], [0, 0]]);
  %88 = qnn.quantize(meta[relay.Constant][14] /* ty=Tensor[(128, 64, 1, 1), float32] */ /* ty=Tensor[(128, 64, 1, 1), float32] */, %conv2d_weight_scale_42, %conv2d_weight_zero_pt_42, out_dtype="int8");
  %89 = qnn.conv2d(%87, %88, %conv2d_data_zero_pt_41, %conv2d_weight_zero_pt_42, %conv2d_data_scale_41, %conv2d_weight_scale_42, strides=[2, 2], padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1], out_dtype="int32");
  %90 = multiply(%conv2d_data_scale_41, %conv2d_weight_scale_42);
  %91 = qnn.dequantize(%89, %90, 0);
  %92 = qnn.quantize(%91, %add_lhs_scale_43, %add_lhs_zero_pt_43, out_dtype="int8");
  %93 = qnn.quantize(meta[relay.Constant][15] /* ty=Tensor[(128, 1, 1), float32] */ /* ty=Tensor[(128, 1, 1), float32] */, %add_rhs_scale_44, %add_rhs_zero_pt_44, out_dtype="int8");
  %94 = qnn.add(%92, %93, %add_lhs_scale_43, %add_lhs_zero_pt_43, %add_rhs_scale_44, %add_rhs_zero_pt_44, %add_out_scale_45, %add_out_zero_pt_45);
  %95 = qnn.dequantize(%94, %add_out_scale_45, %add_out_zero_pt_45);
  %96 = qnn.quantize(%95, %add_rhs_scale_47, %add_rhs_zero_pt_47, out_dtype="int8");
  %97 = qnn.add(%85, %96, %add_lhs_scale_46, %add_lhs_zero_pt_46, %add_rhs_scale_47, %add_rhs_zero_pt_47, %add_out_scale_48, %add_out_zero_pt_48);
  %98 = qnn.dequantize(%97, %add_out_scale_48, %add_out_zero_pt_48);
  %99 = nn.relu(%98);
  %100 = qnn.quantize(%99, %conv2d_data_scale_49, %conv2d_data_zero_pt_49, out_dtype="int8");
  %101 = nn.pad(%100, pad_width=[[0, 0], [0, 0], [1, 1], [1, 1]]);
  %102 = qnn.quantize(meta[relay.Constant][16] /* ty=Tensor[(128, 128, 3, 3), float32] */ /* ty=Tensor[(128, 128, 3, 3), float32] */, %conv2d_weight_scale_50, %conv2d_weight_zero_pt_50, out_dtype="int8");
  %103 = qnn.conv2d(%101, %102, %conv2d_data_zero_pt_49, %conv2d_weight_zero_pt_50, %conv2d_data_scale_49, %conv2d_weight_scale_50, padding=[0, 0, 0, 0], channels=128, kernel_size=[3, 3], out_dtype="int32");
  %104 = multiply(%conv2d_data_scale_49, %conv2d_weight_scale_50);
  %105 = qnn.dequantize(%103, %104, 0);
  %106 = qnn.quantize(%105, %add_lhs_scale_51, %add_lhs_zero_pt_51, out_dtype="int8");
  %107 = qnn.quantize(meta[relay.Constant][17] /* ty=Tensor[(128, 1, 1), float32] */ /* ty=Tensor[(128, 1, 1), float32] */, %add_rhs_scale_52, %add_rhs_zero_pt_52, out_dtype="int8");
  %108 = qnn.add(%106, %107, %add_lhs_scale_51, %add_lhs_zero_pt_51, %add_rhs_scale_52, %add_rhs_zero_pt_52, %add_out_scale_53, %add_out_zero_pt_53);
  %109 = qnn.dequantize(%108, %add_out_scale_53, %add_out_zero_pt_53);
  %110 = nn.relu(%109);
  %111 = qnn.quantize(%110, %conv2d_data_scale_54, %conv2d_data_zero_pt_54, out_dtype="int8");
  %112 = nn.pad(%111, pad_width=[[0, 0], [0, 0], [1, 1], [1, 1]]);
  %113 = qnn.quantize(meta[relay.Constant][18] /* ty=Tensor[(128, 128, 3, 3), float32] */ /* ty=Tensor[(128, 128, 3, 3), float32] */, %conv2d_weight_scale_55, %conv2d_weight_zero_pt_55, out_dtype="int8");
  %114 = qnn.conv2d(%112, %113, %conv2d_data_zero_pt_54, %conv2d_weight_zero_pt_55, %conv2d_data_scale_54, %conv2d_weight_scale_55, padding=[0, 0, 0, 0], channels=128, kernel_size=[3, 3], out_dtype="int32");
  %115 = multiply(%conv2d_data_scale_54, %conv2d_weight_scale_55);
  %116 = qnn.dequantize(%114, %115, 0);
  %117 = qnn.quantize(%116, %add_lhs_scale_56, %add_lhs_zero_pt_56, out_dtype="int8");
  %118 = qnn.quantize(meta[relay.Constant][19] /* ty=Tensor[(128, 1, 1), float32] */ /* ty=Tensor[(128, 1, 1), float32] */, %add_rhs_scale_57, %add_rhs_zero_pt_57, out_dtype="int8");
  %119 = qnn.add(%117, %118, %add_lhs_scale_56, %add_lhs_zero_pt_56, %add_rhs_scale_57, %add_rhs_zero_pt_57, %add_out_scale_58, %add_out_zero_pt_58);
  %120 = qnn.dequantize(%119, %add_out_scale_58, %add_out_zero_pt_58);
  %121 = qnn.quantize(%120, %add_lhs_scale_59, %add_lhs_zero_pt_59, out_dtype="int8");
  %122 = qnn.quantize(%99, %add_rhs_scale_60, %add_rhs_zero_pt_60, out_dtype="int8");
  %123 = qnn.add(%121, %122, %add_lhs_scale_59, %add_lhs_zero_pt_59, %add_rhs_scale_60, %add_rhs_zero_pt_60, %add_out_scale_61, %add_out_zero_pt_61);
  %124 = qnn.dequantize(%123, %add_out_scale_61, %add_out_zero_pt_61);
  %125 = nn.relu(%124);
  %126 = qnn.quantize(%125, %conv2d_data_scale_62, %conv2d_data_zero_pt_62, out_dtype="int8");
  %127 = nn.pad(%126, pad_width=[[0, 0], [0, 0], [1, 1], [1, 1]]);
  %128 = qnn.quantize(meta[relay.Constant][20] /* ty=Tensor[(256, 128, 3, 3), float32] */ /* ty=Tensor[(256, 128, 3, 3), float32] */, %conv2d_weight_scale_63, %conv2d_weight_zero_pt_63, out_dtype="int8");
  %129 = qnn.conv2d(%127, %128, %conv2d_data_zero_pt_62, %conv2d_weight_zero_pt_63, %conv2d_data_scale_62, %conv2d_weight_scale_63, strides=[2, 2], padding=[0, 0, 0, 0], channels=256, kernel_size=[3, 3], out_dtype="int32");
  %130 = multiply(%conv2d_data_scale_62, %conv2d_weight_scale_63);
  %131 = qnn.dequantize(%129, %130, 0);
  %132 = qnn.quantize(%131, %add_lhs_scale_64, %add_lhs_zero_pt_64, out_dtype="int8");
  %133 = qnn.quantize(meta[relay.Constant][21] /* ty=Tensor[(256, 1, 1), float32] */ /* ty=Tensor[(256, 1, 1), float32] */, %add_rhs_scale_65, %add_rhs_zero_pt_65, out_dtype="int8");
  %134 = qnn.add(%132, %133, %add_lhs_scale_64, %add_lhs_zero_pt_64, %add_rhs_scale_65, %add_rhs_zero_pt_65, %add_out_scale_66, %add_out_zero_pt_66);
  %135 = qnn.dequantize(%134, %add_out_scale_66, %add_out_zero_pt_66);
  %136 = nn.relu(%135);
  %137 = qnn.quantize(%136, %conv2d_data_scale_67, %conv2d_data_zero_pt_67, out_dtype="int8");
  %138 = nn.pad(%137, pad_width=[[0, 0], [0, 0], [1, 1], [1, 1]]);
  %139 = qnn.quantize(meta[relay.Constant][22] /* ty=Tensor[(256, 256, 3, 3), float32] */ /* ty=Tensor[(256, 256, 3, 3), float32] */, %conv2d_weight_scale_68, %conv2d_weight_zero_pt_68, out_dtype="int8");
  %140 = qnn.conv2d(%138, %139, %conv2d_data_zero_pt_67, %conv2d_weight_zero_pt_68, %conv2d_data_scale_67, %conv2d_weight_scale_68, padding=[0, 0, 0, 0], channels=256, kernel_size=[3, 3], out_dtype="int32");
  %141 = multiply(%conv2d_data_scale_67, %conv2d_weight_scale_68);
  %142 = qnn.dequantize(%140, %141, 0);
  %143 = qnn.quantize(%142, %add_lhs_scale_69, %add_lhs_zero_pt_69, out_dtype="int8");
  %144 = qnn.quantize(meta[relay.Constant][23] /* ty=Tensor[(256, 1, 1), float32] */ /* ty=Tensor[(256, 1, 1), float32] */, %add_rhs_scale_70, %add_rhs_zero_pt_70, out_dtype="int8");
  %145 = qnn.add(%143, %144, %add_lhs_scale_69, %add_lhs_zero_pt_69, %add_rhs_scale_70, %add_rhs_zero_pt_70, %add_out_scale_71, %add_out_zero_pt_71);
  %146 = qnn.dequantize(%145, %add_out_scale_71, %add_out_zero_pt_71);
  %147 = qnn.quantize(%146, %add_lhs_scale_77, %add_lhs_zero_pt_77, out_dtype="int8");
  %148 = qnn.quantize(%125, %conv2d_data_scale_72, %conv2d_data_zero_pt_72, out_dtype="int8");
  %149 = nn.pad(%148, pad_width=[[0, 0], [0, 0], [0, 0], [0, 0]]);
  %150 = qnn.quantize(meta[relay.Constant][24] /* ty=Tensor[(256, 128, 1, 1), float32] */ /* ty=Tensor[(256, 128, 1, 1), float32] */, %conv2d_weight_scale_73, %conv2d_weight_zero_pt_73, out_dtype="int8");
  %151 = qnn.conv2d(%149, %150, %conv2d_data_zero_pt_72, %conv2d_weight_zero_pt_73, %conv2d_data_scale_72, %conv2d_weight_scale_73, strides=[2, 2], padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1], out_dtype="int32");
  %152 = multiply(%conv2d_data_scale_72, %conv2d_weight_scale_73);
  %153 = qnn.dequantize(%151, %152, 0);
  %154 = qnn.quantize(%153, %add_lhs_scale_74, %add_lhs_zero_pt_74, out_dtype="int8");
  %155 = qnn.quantize(meta[relay.Constant][25] /* ty=Tensor[(256, 1, 1), float32] */ /* ty=Tensor[(256, 1, 1), float32] */, %add_rhs_scale_75, %add_rhs_zero_pt_75, out_dtype="int8");
  %156 = qnn.add(%154, %155, %add_lhs_scale_74, %add_lhs_zero_pt_74, %add_rhs_scale_75, %add_rhs_zero_pt_75, %add_out_scale_76, %add_out_zero_pt_76);
  %157 = qnn.dequantize(%156, %add_out_scale_76, %add_out_zero_pt_76);
  %158 = qnn.quantize(%157, %add_rhs_scale_78, %add_rhs_zero_pt_78, out_dtype="int8");
  %159 = qnn.add(%147, %158, %add_lhs_scale_77, %add_lhs_zero_pt_77, %add_rhs_scale_78, %add_rhs_zero_pt_78, %add_out_scale_79, %add_out_zero_pt_79);
  %160 = qnn.dequantize(%159, %add_out_scale_79, %add_out_zero_pt_79);
  %161 = nn.relu(%160);
  %162 = qnn.quantize(%161, %conv2d_data_scale_80, %conv2d_data_zero_pt_80, out_dtype="int8");
  %163 = nn.pad(%162, pad_width=[[0, 0], [0, 0], [1, 1], [1, 1]]);
  %164 = qnn.quantize(meta[relay.Constant][26] /* ty=Tensor[(256, 256, 3, 3), float32] */ /* ty=Tensor[(256, 256, 3, 3), float32] */, %conv2d_weight_scale_81, %conv2d_weight_zero_pt_81, out_dtype="int8");
  %165 = qnn.conv2d(%163, %164, %conv2d_data_zero_pt_80, %conv2d_weight_zero_pt_81, %conv2d_data_scale_80, %conv2d_weight_scale_81, padding=[0, 0, 0, 0], channels=256, kernel_size=[3, 3], out_dtype="int32");
  %166 = multiply(%conv2d_data_scale_80, %conv2d_weight_scale_81);
  %167 = qnn.dequantize(%165, %166, 0);
  %168 = qnn.quantize(%167, %add_lhs_scale_82, %add_lhs_zero_pt_82, out_dtype="int8");
  %169 = qnn.quantize(meta[relay.Constant][27] /* ty=Tensor[(256, 1, 1), float32] */ /* ty=Tensor[(256, 1, 1), float32] */, %add_rhs_scale_83, %add_rhs_zero_pt_83, out_dtype="int8");
  %170 = qnn.add(%168, %169, %add_lhs_scale_82, %add_lhs_zero_pt_82, %add_rhs_scale_83, %add_rhs_zero_pt_83, %add_out_scale_84, %add_out_zero_pt_84);
  %171 = qnn.dequantize(%170, %add_out_scale_84, %add_out_zero_pt_84);
  %172 = nn.relu(%171);
  %173 = qnn.quantize(%172, %conv2d_data_scale_85, %conv2d_data_zero_pt_85, out_dtype="int8");
  %174 = nn.pad(%173, pad_width=[[0, 0], [0, 0], [1, 1], [1, 1]]);
  %175 = qnn.quantize(meta[relay.Constant][28] /* ty=Tensor[(256, 256, 3, 3), float32] */ /* ty=Tensor[(256, 256, 3, 3), float32] */, %conv2d_weight_scale_86, %conv2d_weight_zero_pt_86, out_dtype="int8");
  %176 = qnn.conv2d(%174, %175, %conv2d_data_zero_pt_85, %conv2d_weight_zero_pt_86, %conv2d_data_scale_85, %conv2d_weight_scale_86, padding=[0, 0, 0, 0], channels=256, kernel_size=[3, 3], out_dtype="int32");
  %177 = multiply(%conv2d_data_scale_85, %conv2d_weight_scale_86);
  %178 = qnn.dequantize(%176, %177, 0);
  %179 = qnn.quantize(%178, %add_lhs_scale_87, %add_lhs_zero_pt_87, out_dtype="int8");
  %180 = qnn.quantize(meta[relay.Constant][29] /* ty=Tensor[(256, 1, 1), float32] */ /* ty=Tensor[(256, 1, 1), float32] */, %add_rhs_scale_88, %add_rhs_zero_pt_88, out_dtype="int8");
  %181 = qnn.add(%179, %180, %add_lhs_scale_87, %add_lhs_zero_pt_87, %add_rhs_scale_88, %add_rhs_zero_pt_88, %add_out_scale_89, %add_out_zero_pt_89);
  %182 = qnn.dequantize(%181, %add_out_scale_89, %add_out_zero_pt_89);
  %183 = qnn.quantize(%182, %add_lhs_scale_90, %add_lhs_zero_pt_90, out_dtype="int8");
  %184 = qnn.quantize(%161, %add_rhs_scale_91, %add_rhs_zero_pt_91, out_dtype="int8");
  %185 = qnn.add(%183, %184, %add_lhs_scale_90, %add_lhs_zero_pt_90, %add_rhs_scale_91, %add_rhs_zero_pt_91, %add_out_scale_92, %add_out_zero_pt_92);
  %186 = qnn.dequantize(%185, %add_out_scale_92, %add_out_zero_pt_92);
  %187 = nn.relu(%186);
  %188 = qnn.quantize(%187, %conv2d_data_scale_93, %conv2d_data_zero_pt_93, out_dtype="int8");
  %189 = nn.pad(%188, pad_width=[[0, 0], [0, 0], [1, 1], [1, 1]]);
  %190 = qnn.quantize(meta[relay.Constant][30] /* ty=Tensor[(512, 256, 3, 3), float32] */ /* ty=Tensor[(512, 256, 3, 3), float32] */, %conv2d_weight_scale_94, %conv2d_weight_zero_pt_94, out_dtype="int8");
  %191 = qnn.conv2d(%189, %190, %conv2d_data_zero_pt_93, %conv2d_weight_zero_pt_94, %conv2d_data_scale_93, %conv2d_weight_scale_94, strides=[2, 2], padding=[0, 0, 0, 0], channels=512, kernel_size=[3, 3], out_dtype="int32");
  %192 = multiply(%conv2d_data_scale_93, %conv2d_weight_scale_94);
  %193 = qnn.dequantize(%191, %192, 0);
  %194 = qnn.quantize(%193, %add_lhs_scale_95, %add_lhs_zero_pt_95, out_dtype="int8");
  %195 = qnn.quantize(meta[relay.Constant][31] /* ty=Tensor[(512, 1, 1), float32] */ /* ty=Tensor[(512, 1, 1), float32] */, %add_rhs_scale_96, %add_rhs_zero_pt_96, out_dtype="int8");
  %196 = qnn.add(%194, %195, %add_lhs_scale_95, %add_lhs_zero_pt_95, %add_rhs_scale_96, %add_rhs_zero_pt_96, %add_out_scale_97, %add_out_zero_pt_97);
  %197 = qnn.dequantize(%196, %add_out_scale_97, %add_out_zero_pt_97);
  %198 = nn.relu(%197);
  %199 = qnn.quantize(%198, %conv2d_data_scale_98, %conv2d_data_zero_pt_98, out_dtype="int8");
  %200 = nn.pad(%199, pad_width=[[0, 0], [0, 0], [1, 1], [1, 1]]);
  %201 = qnn.quantize(meta[relay.Constant][32] /* ty=Tensor[(512, 512, 3, 3), float32] */ /* ty=Tensor[(512, 512, 3, 3), float32] */, %conv2d_weight_scale_99, %conv2d_weight_zero_pt_99, out_dtype="int8");
  %202 = qnn.conv2d(%200, %201, %conv2d_data_zero_pt_98, %conv2d_weight_zero_pt_99, %conv2d_data_scale_98, %conv2d_weight_scale_99, padding=[0, 0, 0, 0], channels=512, kernel_size=[3, 3], out_dtype="int32");
  %203 = multiply(%conv2d_data_scale_98, %conv2d_weight_scale_99);
  %204 = qnn.dequantize(%202, %203, 0);
  %205 = qnn.quantize(%204, %add_lhs_scale_100, %add_lhs_zero_pt_100, out_dtype="int8");
  %206 = qnn.quantize(meta[relay.Constant][33] /* ty=Tensor[(512, 1, 1), float32] */ /* ty=Tensor[(512, 1, 1), float32] */, %add_rhs_scale_101, %add_rhs_zero_pt_101, out_dtype="int8");
  %207 = qnn.add(%205, %206, %add_lhs_scale_100, %add_lhs_zero_pt_100, %add_rhs_scale_101, %add_rhs_zero_pt_101, %add_out_scale_102, %add_out_zero_pt_102);
  %208 = qnn.dequantize(%207, %add_out_scale_102, %add_out_zero_pt_102);
  %209 = qnn.quantize(%208, %add_lhs_scale_108, %add_lhs_zero_pt_108, out_dtype="int8");
  %210 = qnn.quantize(%187, %conv2d_data_scale_103, %conv2d_data_zero_pt_103, out_dtype="int8");
  %211 = nn.pad(%210, pad_width=[[0, 0], [0, 0], [0, 0], [0, 0]]);
  %212 = qnn.quantize(meta[relay.Constant][34] /* ty=Tensor[(512, 256, 1, 1), float32] */ /* ty=Tensor[(512, 256, 1, 1), float32] */, %conv2d_weight_scale_104, %conv2d_weight_zero_pt_104, out_dtype="int8");
  %213 = qnn.conv2d(%211, %212, %conv2d_data_zero_pt_103, %conv2d_weight_zero_pt_104, %conv2d_data_scale_103, %conv2d_weight_scale_104, strides=[2, 2], padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1], out_dtype="int32");
  %214 = multiply(%conv2d_data_scale_103, %conv2d_weight_scale_104);
  %215 = qnn.dequantize(%213, %214, 0);
  %216 = qnn.quantize(%215, %add_lhs_scale_105, %add_lhs_zero_pt_105, out_dtype="int8");
  %217 = qnn.quantize(meta[relay.Constant][35] /* ty=Tensor[(512, 1, 1), float32] */ /* ty=Tensor[(512, 1, 1), float32] */, %add_rhs_scale_106, %add_rhs_zero_pt_106, out_dtype="int8");
  %218 = qnn.add(%216, %217, %add_lhs_scale_105, %add_lhs_zero_pt_105, %add_rhs_scale_106, %add_rhs_zero_pt_106, %add_out_scale_107, %add_out_zero_pt_107);
  %219 = qnn.dequantize(%218, %add_out_scale_107, %add_out_zero_pt_107);
  %220 = qnn.quantize(%219, %add_rhs_scale_109, %add_rhs_zero_pt_109, out_dtype="int8");
  %221 = qnn.add(%209, %220, %add_lhs_scale_108, %add_lhs_zero_pt_108, %add_rhs_scale_109, %add_rhs_zero_pt_109, %add_out_scale_110, %add_out_zero_pt_110);
  %222 = qnn.dequantize(%221, %add_out_scale_110, %add_out_zero_pt_110);
  %223 = nn.relu(%222);
  %224 = qnn.quantize(%223, %conv2d_data_scale_111, %conv2d_data_zero_pt_111, out_dtype="int8");
  %225 = nn.pad(%224, pad_width=[[0, 0], [0, 0], [1, 1], [1, 1]]);
  %226 = qnn.quantize(meta[relay.Constant][36] /* ty=Tensor[(512, 512, 3, 3), float32] */ /* ty=Tensor[(512, 512, 3, 3), float32] */, %conv2d_weight_scale_112, %conv2d_weight_zero_pt_112, out_dtype="int8");
  %227 = qnn.conv2d(%225, %226, %conv2d_data_zero_pt_111, %conv2d_weight_zero_pt_112, %conv2d_data_scale_111, %conv2d_weight_scale_112, padding=[0, 0, 0, 0], channels=512, kernel_size=[3, 3], out_dtype="int32");
  %228 = multiply(%conv2d_data_scale_111, %conv2d_weight_scale_112);
  %229 = qnn.dequantize(%227, %228, 0);
  %230 = qnn.quantize(%229, %add_lhs_scale_113, %add_lhs_zero_pt_113, out_dtype="int8");
  %231 = qnn.quantize(meta[relay.Constant][37] /* ty=Tensor[(512, 1, 1), float32] */ /* ty=Tensor[(512, 1, 1), float32] */, %add_rhs_scale_114, %add_rhs_zero_pt_114, out_dtype="int8");
  %232 = qnn.add(%230, %231, %add_lhs_scale_113, %add_lhs_zero_pt_113, %add_rhs_scale_114, %add_rhs_zero_pt_114, %add_out_scale_115, %add_out_zero_pt_115);
  %233 = qnn.dequantize(%232, %add_out_scale_115, %add_out_zero_pt_115);
  %234 = nn.relu(%233);
  %235 = qnn.quantize(%234, %conv2d_data_scale_116, %conv2d_data_zero_pt_116, out_dtype="int8");
  %236 = nn.pad(%235, pad_width=[[0, 0], [0, 0], [1, 1], [1, 1]]);
  %237 = qnn.quantize(meta[relay.Constant][38] /* ty=Tensor[(512, 512, 3, 3), float32] */ /* ty=Tensor[(512, 512, 3, 3), float32] */, %conv2d_weight_scale_117, %conv2d_weight_zero_pt_117, out_dtype="int8");
  %238 = qnn.conv2d(%236, %237, %conv2d_data_zero_pt_116, %conv2d_weight_zero_pt_117, %conv2d_data_scale_116, %conv2d_weight_scale_117, padding=[0, 0, 0, 0], channels=512, kernel_size=[3, 3], out_dtype="int32");
  %239 = multiply(%conv2d_data_scale_116, %conv2d_weight_scale_117);
  %240 = qnn.dequantize(%238, %239, 0);
  %241 = qnn.quantize(%240, %add_lhs_scale_118, %add_lhs_zero_pt_118, out_dtype="int8");
  %242 = qnn.quantize(meta[relay.Constant][39] /* ty=Tensor[(512, 1, 1), float32] */ /* ty=Tensor[(512, 1, 1), float32] */, %add_rhs_scale_119, %add_rhs_zero_pt_119, out_dtype="int8");
  %243 = qnn.add(%241, %242, %add_lhs_scale_118, %add_lhs_zero_pt_118, %add_rhs_scale_119, %add_rhs_zero_pt_119, %add_out_scale_120, %add_out_zero_pt_120);
  %244 = qnn.dequantize(%243, %add_out_scale_120, %add_out_zero_pt_120);
  %245 = qnn.quantize(%244, %add_lhs_scale_121, %add_lhs_zero_pt_121, out_dtype="int8");
  %246 = qnn.quantize(%223, %add_rhs_scale_122, %add_rhs_zero_pt_122, out_dtype="int8");
  %247 = qnn.add(%245, %246, %add_lhs_scale_121, %add_lhs_zero_pt_121, %add_rhs_scale_122, %add_rhs_zero_pt_122, %add_out_scale_123, %add_out_zero_pt_123);
  %248 = qnn.dequantize(%247, %add_out_scale_123, %add_out_zero_pt_123);
  %249 = nn.relu(%248);
  %250 = nn.adaptive_avg_pool2d(%249, output_size=[1, 1]);
  %251 = nn.batch_flatten(%250);
  %252 = qnn.quantize(%251, %dense_data_scale_124, %dense_data_zero_pt_124, out_dtype="int8");
  %253 = qnn.quantize(meta[relay.Constant][40] /* ty=Tensor[(1000, 512), float32] */ /* ty=Tensor[(1000, 512), float32] */, %dense_weight_scale_125, %dense_weight_zero_pt_125, out_dtype="int8");
  %254 = qnn.dense(%252, %253, %dense_data_zero_pt_124, %dense_weight_zero_pt_125, %dense_data_scale_124, %dense_weight_scale_125, units=1000, out_dtype="int32");
  %255 = multiply(%dense_data_scale_124, %dense_weight_scale_125);
  %256 = qnn.dequantize(%254, %255, 0);
  %257 = qnn.quantize(%256, %add_lhs_scale_126, %add_lhs_zero_pt_126, out_dtype="int8");
  %258 = qnn.quantize(meta[relay.Constant][41] /* ty=Tensor[(1000), float32] */ /* ty=Tensor[(1000), float32] */, %add_rhs_scale_127, %add_rhs_zero_pt_127, out_dtype="int8");
  %259 = qnn.add(%257, %258, %add_lhs_scale_126, %add_lhs_zero_pt_126, %add_rhs_scale_127, %add_rhs_zero_pt_127, %add_out_scale_128, %add_out_zero_pt_128);
  qnn.dequantize(%259, %add_out_scale_128, %add_out_zero_pt_128)
}

skip_layers_ptr 0
skip_layers_ptr 0
skip_layers_ptr 0
skip_layers_ptr 0
skip_layers_ptr 0
skip_layers_ptr 0
skip_layers_ptr 0
skip_layers_ptr 0
skip_layers_ptr 0
skip_layers_ptr 0
skip_layers_ptr 0
skip_layers_ptr 0
skip_layers_ptr 0
skip_layers_ptr 0
skip_layers_ptr 0
skip_layers_ptr 0
skip_layers_ptr 0
skip_layers_ptr 0
skip_layers_ptr 0
skip_layers_ptr 0
fn (%input: Tensor[(1, 3, 224, 224), float32], %conv2d_data_scale_0, %conv2d_weight_scale_1, %add_lhs_scale_2, %add_rhs_scale_3, %add_out_scale_4, %conv2d_data_scale_5, %conv2d_weight_scale_6, %add_lhs_scale_7, %add_rhs_scale_8, %add_out_scale_9, %conv2d_data_scale_10, %conv2d_weight_scale_11, %add_lhs_scale_12, %add_rhs_scale_13, %add_out_scale_14, %add_lhs_scale_15, %add_rhs_scale_16, %add_out_scale_17, %conv2d_data_scale_18, %conv2d_weight_scale_19, %add_lhs_scale_20, %add_rhs_scale_21, %add_out_scale_22, %conv2d_data_scale_23, %conv2d_weight_scale_24, %add_lhs_scale_25, %add_rhs_scale_26, %add_out_scale_27, %add_lhs_scale_28, %add_rhs_scale_29, %add_out_scale_30, %conv2d_data_scale_31, %conv2d_weight_scale_32, %add_lhs_scale_33, %add_rhs_scale_34, %add_out_scale_35, %conv2d_data_scale_36, %conv2d_weight_scale_37, %add_lhs_scale_38, %add_rhs_scale_39, %add_out_scale_40, %conv2d_data_scale_41, %conv2d_weight_scale_42, %add_lhs_scale_43, %add_rhs_scale_44, %add_out_scale_45, %add_lhs_scale_46, %add_rhs_scale_47, %add_out_scale_48, %conv2d_data_scale_49, %conv2d_weight_scale_50, %add_lhs_scale_51, %add_rhs_scale_52, %add_out_scale_53, %conv2d_data_scale_54, %conv2d_weight_scale_55, %add_lhs_scale_56, %add_rhs_scale_57, %add_out_scale_58, %add_lhs_scale_59, %add_rhs_scale_60, %add_out_scale_61, %conv2d_data_scale_62, %conv2d_weight_scale_63, %add_lhs_scale_64, %add_rhs_scale_65, %add_out_scale_66, %conv2d_data_scale_67, %conv2d_weight_scale_68, %add_lhs_scale_69, %add_rhs_scale_70, %add_out_scale_71, %conv2d_data_scale_72, %conv2d_weight_scale_73, %add_lhs_scale_74, %add_rhs_scale_75, %add_out_scale_76, %add_lhs_scale_77, %add_rhs_scale_78, %add_out_scale_79, %conv2d_data_scale_80, %conv2d_weight_scale_81, %add_lhs_scale_82, %add_rhs_scale_83, %add_out_scale_84, %conv2d_data_scale_85, %conv2d_weight_scale_86, %add_lhs_scale_87, %add_rhs_scale_88, %add_out_scale_89, %add_lhs_scale_90, %add_rhs_scale_91, %add_out_scale_92, %conv2d_data_scale_93, %conv2d_weight_scale_94, %add_lhs_scale_95, %add_rhs_scale_96, %add_out_scale_97, %conv2d_data_scale_98, %conv2d_weight_scale_99, %add_lhs_scale_100, %add_rhs_scale_101, %add_out_scale_102, %conv2d_data_scale_103, %conv2d_weight_scale_104, %add_lhs_scale_105, %add_rhs_scale_106, %add_out_scale_107, %add_lhs_scale_108, %add_rhs_scale_109, %add_out_scale_110, %conv2d_data_scale_111, %conv2d_weight_scale_112, %add_lhs_scale_113, %add_rhs_scale_114, %add_out_scale_115, %conv2d_data_scale_116, %conv2d_weight_scale_117, %add_lhs_scale_118, %add_rhs_scale_119, %add_out_scale_120, %add_lhs_scale_121, %add_rhs_scale_122, %add_out_scale_123, %dense_data_scale_124, %dense_weight_scale_125, %add_lhs_scale_126, %add_rhs_scale_127, %add_out_scale_128, %conv2d_data_zero_pt_0, %conv2d_weight_zero_pt_1, %add_lhs_zero_pt_2, %add_rhs_zero_pt_3, %add_out_zero_pt_4, %conv2d_data_zero_pt_5, %conv2d_weight_zero_pt_6, %add_lhs_zero_pt_7, %add_rhs_zero_pt_8, %add_out_zero_pt_9, %conv2d_data_zero_pt_10, %conv2d_weight_zero_pt_11, %add_lhs_zero_pt_12, %add_rhs_zero_pt_13, %add_out_zero_pt_14, %add_lhs_zero_pt_15, %add_rhs_zero_pt_16, %add_out_zero_pt_17, %conv2d_data_zero_pt_18, %conv2d_weight_zero_pt_19, %add_lhs_zero_pt_20, %add_rhs_zero_pt_21, %add_out_zero_pt_22, %conv2d_data_zero_pt_23, %conv2d_weight_zero_pt_24, %add_lhs_zero_pt_25, %add_rhs_zero_pt_26, %add_out_zero_pt_27, %add_lhs_zero_pt_28, %add_rhs_zero_pt_29, %add_out_zero_pt_30, %conv2d_data_zero_pt_31, %conv2d_weight_zero_pt_32, %add_lhs_zero_pt_33, %add_rhs_zero_pt_34, %add_out_zero_pt_35, %conv2d_data_zero_pt_36, %conv2d_weight_zero_pt_37, %add_lhs_zero_pt_38, %add_rhs_zero_pt_39, %add_out_zero_pt_40, %conv2d_data_zero_pt_41, %conv2d_weight_zero_pt_42, %add_lhs_zero_pt_43, %add_rhs_zero_pt_44, %add_out_zero_pt_45, %add_lhs_zero_pt_46, %add_rhs_zero_pt_47, %add_out_zero_pt_48, %conv2d_data_zero_pt_49, %conv2d_weight_zero_pt_50, %add_lhs_zero_pt_51, %add_rhs_zero_pt_52, %add_out_zero_pt_53, %conv2d_data_zero_pt_54, %conv2d_weight_zero_pt_55, %add_lhs_zero_pt_56, %add_rhs_zero_pt_57, %add_out_zero_pt_58, %add_lhs_zero_pt_59, %add_rhs_zero_pt_60, %add_out_zero_pt_61, %conv2d_data_zero_pt_62, %conv2d_weight_zero_pt_63, %add_lhs_zero_pt_64, %add_rhs_zero_pt_65, %add_out_zero_pt_66, %conv2d_data_zero_pt_67, %conv2d_weight_zero_pt_68, %add_lhs_zero_pt_69, %add_rhs_zero_pt_70, %add_out_zero_pt_71, %conv2d_data_zero_pt_72, %conv2d_weight_zero_pt_73, %add_lhs_zero_pt_74, %add_rhs_zero_pt_75, %add_out_zero_pt_76, %add_lhs_zero_pt_77, %add_rhs_zero_pt_78, %add_out_zero_pt_79, %conv2d_data_zero_pt_80, %conv2d_weight_zero_pt_81, %add_lhs_zero_pt_82, %add_rhs_zero_pt_83, %add_out_zero_pt_84, %conv2d_data_zero_pt_85, %conv2d_weight_zero_pt_86, %add_lhs_zero_pt_87, %add_rhs_zero_pt_88, %add_out_zero_pt_89, %add_lhs_zero_pt_90, %add_rhs_zero_pt_91, %add_out_zero_pt_92, %conv2d_data_zero_pt_93, %conv2d_weight_zero_pt_94, %add_lhs_zero_pt_95, %add_rhs_zero_pt_96, %add_out_zero_pt_97, %conv2d_data_zero_pt_98, %conv2d_weight_zero_pt_99, %add_lhs_zero_pt_100, %add_rhs_zero_pt_101, %add_out_zero_pt_102, %conv2d_data_zero_pt_103, %conv2d_weight_zero_pt_104, %add_lhs_zero_pt_105, %add_rhs_zero_pt_106, %add_out_zero_pt_107, %add_lhs_zero_pt_108, %add_rhs_zero_pt_109, %add_out_zero_pt_110, %conv2d_data_zero_pt_111, %conv2d_weight_zero_pt_112, %add_lhs_zero_pt_113, %add_rhs_zero_pt_114, %add_out_zero_pt_115, %conv2d_data_zero_pt_116, %conv2d_weight_zero_pt_117, %add_lhs_zero_pt_118, %add_rhs_zero_pt_119, %add_out_zero_pt_120, %add_lhs_zero_pt_121, %add_rhs_zero_pt_122, %add_out_zero_pt_123, %dense_data_zero_pt_124, %dense_weight_zero_pt_125, %add_lhs_zero_pt_126, %add_rhs_zero_pt_127, %add_out_zero_pt_128) {
  %0 = qnn.quantize(%input, %conv2d_data_scale_0, %conv2d_data_zero_pt_0, out_dtype="int8");
  %1 = nn.pad(%0, pad_width=[[0, 0], [0, 0], [3, 3], [3, 3]]);
  %2 = qnn.quantize(meta[relay.Constant][0] /* ty=Tensor[(64, 3, 7, 7), float32] */ /* ty=Tensor[(64, 3, 7, 7), float32] */, %conv2d_weight_scale_1, %conv2d_weight_zero_pt_1, out_dtype="int8");
  %3 = qnn.conv2d(%1, %2, %conv2d_data_zero_pt_0, %conv2d_weight_zero_pt_1, %conv2d_data_scale_0, %conv2d_weight_scale_1, strides=[2, 2], padding=[0, 0, 0, 0], channels=64, kernel_size=[7, 7], out_dtype="int32");
  %4 = multiply(%conv2d_data_scale_0, %conv2d_weight_scale_1);
  %5 = qnn.dequantize(%3, %4, 0);
  %6 = qnn.quantize(%5, %add_lhs_scale_2, %add_lhs_zero_pt_2, out_dtype="int8");
  %7 = qnn.quantize(meta[relay.Constant][1] /* ty=Tensor[(64, 1, 1), float32] */ /* ty=Tensor[(64, 1, 1), float32] */, %add_rhs_scale_3, %add_rhs_zero_pt_3, out_dtype="int8");
  %8 = qnn.add(%6, %7, %add_lhs_scale_2, %add_lhs_zero_pt_2, %add_rhs_scale_3, %add_rhs_zero_pt_3, %add_out_scale_4, %add_out_zero_pt_4);
  %9 = qnn.dequantize(%8, %add_out_scale_4, %add_out_zero_pt_4);
  %10 = nn.relu(%9);
  %11 = nn.max_pool2d(%10, pool_size=[3, 3], strides=[2, 2], padding=[1, 1, 1, 1]);
  %12 = qnn.quantize(%11, %conv2d_data_scale_5, %conv2d_data_zero_pt_5, out_dtype="int8");
  %13 = nn.pad(%12, pad_width=[[0, 0], [0, 0], [1, 1], [1, 1]]);
  %14 = qnn.quantize(meta[relay.Constant][2] /* ty=Tensor[(64, 64, 3, 3), float32] */ /* ty=Tensor[(64, 64, 3, 3), float32] */, %conv2d_weight_scale_6, %conv2d_weight_zero_pt_6, out_dtype="int8");
  %15 = qnn.conv2d(%13, %14, %conv2d_data_zero_pt_5, %conv2d_weight_zero_pt_6, %conv2d_data_scale_5, %conv2d_weight_scale_6, padding=[0, 0, 0, 0], channels=64, kernel_size=[3, 3], out_dtype="int32");
  %16 = multiply(%conv2d_data_scale_5, %conv2d_weight_scale_6);
  %17 = qnn.dequantize(%15, %16, 0);
  %18 = qnn.quantize(%17, %add_lhs_scale_7, %add_lhs_zero_pt_7, out_dtype="int8");
  %19 = qnn.quantize(meta[relay.Constant][3] /* ty=Tensor[(64, 1, 1), float32] */ /* ty=Tensor[(64, 1, 1), float32] */, %add_rhs_scale_8, %add_rhs_zero_pt_8, out_dtype="int8");
  %20 = qnn.add(%18, %19, %add_lhs_scale_7, %add_lhs_zero_pt_7, %add_rhs_scale_8, %add_rhs_zero_pt_8, %add_out_scale_9, %add_out_zero_pt_9);
  %21 = qnn.dequantize(%20, %add_out_scale_9, %add_out_zero_pt_9);
  %22 = nn.relu(%21);
  %23 = qnn.quantize(%22, %conv2d_data_scale_10, %conv2d_data_zero_pt_10, out_dtype="int8");
  %24 = nn.pad(%23, pad_width=[[0, 0], [0, 0], [1, 1], [1, 1]]);
  %25 = qnn.quantize(meta[relay.Constant][4] /* ty=Tensor[(64, 64, 3, 3), float32] */ /* ty=Tensor[(64, 64, 3, 3), float32] */, %conv2d_weight_scale_11, %conv2d_weight_zero_pt_11, out_dtype="int8");
  %26 = qnn.conv2d(%24, %25, %conv2d_data_zero_pt_10, %conv2d_weight_zero_pt_11, %conv2d_data_scale_10, %conv2d_weight_scale_11, padding=[0, 0, 0, 0], channels=64, kernel_size=[3, 3], out_dtype="int32");
  %27 = multiply(%conv2d_data_scale_10, %conv2d_weight_scale_11);
  %28 = qnn.dequantize(%26, %27, 0);
  %29 = qnn.quantize(%28, %add_lhs_scale_12, %add_lhs_zero_pt_12, out_dtype="int8");
  %30 = qnn.quantize(meta[relay.Constant][5] /* ty=Tensor[(64, 1, 1), float32] */ /* ty=Tensor[(64, 1, 1), float32] */, %add_rhs_scale_13, %add_rhs_zero_pt_13, out_dtype="int8");
  %31 = qnn.add(%29, %30, %add_lhs_scale_12, %add_lhs_zero_pt_12, %add_rhs_scale_13, %add_rhs_zero_pt_13, %add_out_scale_14, %add_out_zero_pt_14);
  %32 = qnn.dequantize(%31, %add_out_scale_14, %add_out_zero_pt_14);
  %33 = qnn.quantize(%32, %add_lhs_scale_15, %add_lhs_zero_pt_15, out_dtype="int8");
  %34 = qnn.quantize(%11, %add_rhs_scale_16, %add_rhs_zero_pt_16, out_dtype="int8");
  %35 = qnn.add(%33, %34, %add_lhs_scale_15, %add_lhs_zero_pt_15, %add_rhs_scale_16, %add_rhs_zero_pt_16, %add_out_scale_17, %add_out_zero_pt_17);
  %36 = qnn.dequantize(%35, %add_out_scale_17, %add_out_zero_pt_17);
  %37 = nn.relu(%36);
  %38 = qnn.quantize(%37, %conv2d_data_scale_18, %conv2d_data_zero_pt_18, out_dtype="int8");
  %39 = nn.pad(%38, pad_width=[[0, 0], [0, 0], [1, 1], [1, 1]]);
  %40 = qnn.quantize(meta[relay.Constant][6] /* ty=Tensor[(64, 64, 3, 3), float32] */ /* ty=Tensor[(64, 64, 3, 3), float32] */, %conv2d_weight_scale_19, %conv2d_weight_zero_pt_19, out_dtype="int8");
  %41 = qnn.conv2d(%39, %40, %conv2d_data_zero_pt_18, %conv2d_weight_zero_pt_19, %conv2d_data_scale_18, %conv2d_weight_scale_19, padding=[0, 0, 0, 0], channels=64, kernel_size=[3, 3], out_dtype="int32");
  %42 = multiply(%conv2d_data_scale_18, %conv2d_weight_scale_19);
  %43 = qnn.dequantize(%41, %42, 0);
  %44 = qnn.quantize(%43, %add_lhs_scale_20, %add_lhs_zero_pt_20, out_dtype="int8");
  %45 = qnn.quantize(meta[relay.Constant][7] /* ty=Tensor[(64, 1, 1), float32] */ /* ty=Tensor[(64, 1, 1), float32] */, %add_rhs_scale_21, %add_rhs_zero_pt_21, out_dtype="int8");
  %46 = qnn.add(%44, %45, %add_lhs_scale_20, %add_lhs_zero_pt_20, %add_rhs_scale_21, %add_rhs_zero_pt_21, %add_out_scale_22, %add_out_zero_pt_22);
  %47 = qnn.dequantize(%46, %add_out_scale_22, %add_out_zero_pt_22);
  %48 = nn.relu(%47);
  %49 = qnn.quantize(%48, %conv2d_data_scale_23, %conv2d_data_zero_pt_23, out_dtype="int8");
  %50 = nn.pad(%49, pad_width=[[0, 0], [0, 0], [1, 1], [1, 1]]);
  %51 = qnn.quantize(meta[relay.Constant][8] /* ty=Tensor[(64, 64, 3, 3), float32] */ /* ty=Tensor[(64, 64, 3, 3), float32] */, %conv2d_weight_scale_24, %conv2d_weight_zero_pt_24, out_dtype="int8");
  %52 = qnn.conv2d(%50, %51, %conv2d_data_zero_pt_23, %conv2d_weight_zero_pt_24, %conv2d_data_scale_23, %conv2d_weight_scale_24, padding=[0, 0, 0, 0], channels=64, kernel_size=[3, 3], out_dtype="int32");
  %53 = multiply(%conv2d_data_scale_23, %conv2d_weight_scale_24);
  %54 = qnn.dequantize(%52, %53, 0);
  %55 = qnn.quantize(%54, %add_lhs_scale_25, %add_lhs_zero_pt_25, out_dtype="int8");
  %56 = qnn.quantize(meta[relay.Constant][9] /* ty=Tensor[(64, 1, 1), float32] */ /* ty=Tensor[(64, 1, 1), float32] */, %add_rhs_scale_26, %add_rhs_zero_pt_26, out_dtype="int8");
  %57 = qnn.add(%55, %56, %add_lhs_scale_25, %add_lhs_zero_pt_25, %add_rhs_scale_26, %add_rhs_zero_pt_26, %add_out_scale_27, %add_out_zero_pt_27);
  %58 = qnn.dequantize(%57, %add_out_scale_27, %add_out_zero_pt_27);
  %59 = qnn.quantize(%58, %add_lhs_scale_28, %add_lhs_zero_pt_28, out_dtype="int8");
  %60 = qnn.quantize(%37, %add_rhs_scale_29, %add_rhs_zero_pt_29, out_dtype="int8");
  %61 = qnn.add(%59, %60, %add_lhs_scale_28, %add_lhs_zero_pt_28, %add_rhs_scale_29, %add_rhs_zero_pt_29, %add_out_scale_30, %add_out_zero_pt_30);
  %62 = qnn.dequantize(%61, %add_out_scale_30, %add_out_zero_pt_30);
  %63 = nn.relu(%62);
  %64 = qnn.quantize(%63, %conv2d_data_scale_31, %conv2d_data_zero_pt_31, out_dtype="int8");
  %65 = nn.pad(%64, pad_width=[[0, 0], [0, 0], [1, 1], [1, 1]]);
  %66 = qnn.quantize(meta[relay.Constant][10] /* ty=Tensor[(128, 64, 3, 3), float32] */ /* ty=Tensor[(128, 64, 3, 3), float32] */, %conv2d_weight_scale_32, %conv2d_weight_zero_pt_32, out_dtype="int8");
  %67 = qnn.conv2d(%65, %66, %conv2d_data_zero_pt_31, %conv2d_weight_zero_pt_32, %conv2d_data_scale_31, %conv2d_weight_scale_32, strides=[2, 2], padding=[0, 0, 0, 0], channels=128, kernel_size=[3, 3], out_dtype="int32");
  %68 = multiply(%conv2d_data_scale_31, %conv2d_weight_scale_32);
  %69 = qnn.dequantize(%67, %68, 0);
  %70 = qnn.quantize(%69, %add_lhs_scale_33, %add_lhs_zero_pt_33, out_dtype="int8");
  %71 = qnn.quantize(meta[relay.Constant][11] /* ty=Tensor[(128, 1, 1), float32] */ /* ty=Tensor[(128, 1, 1), float32] */, %add_rhs_scale_34, %add_rhs_zero_pt_34, out_dtype="int8");
  %72 = qnn.add(%70, %71, %add_lhs_scale_33, %add_lhs_zero_pt_33, %add_rhs_scale_34, %add_rhs_zero_pt_34, %add_out_scale_35, %add_out_zero_pt_35);
  %73 = qnn.dequantize(%72, %add_out_scale_35, %add_out_zero_pt_35);
  %74 = nn.relu(%73);
  %75 = qnn.quantize(%74, %conv2d_data_scale_36, %conv2d_data_zero_pt_36, out_dtype="int8");
  %76 = nn.pad(%75, pad_width=[[0, 0], [0, 0], [1, 1], [1, 1]]);
  %77 = qnn.quantize(meta[relay.Constant][12] /* ty=Tensor[(128, 128, 3, 3), float32] */ /* ty=Tensor[(128, 128, 3, 3), float32] */, %conv2d_weight_scale_37, %conv2d_weight_zero_pt_37, out_dtype="int8");
  %78 = qnn.conv2d(%76, %77, %conv2d_data_zero_pt_36, %conv2d_weight_zero_pt_37, %conv2d_data_scale_36, %conv2d_weight_scale_37, padding=[0, 0, 0, 0], channels=128, kernel_size=[3, 3], out_dtype="int32");
  %79 = multiply(%conv2d_data_scale_36, %conv2d_weight_scale_37);
  %80 = qnn.dequantize(%78, %79, 0);
  %81 = qnn.quantize(%80, %add_lhs_scale_38, %add_lhs_zero_pt_38, out_dtype="int8");
  %82 = qnn.quantize(meta[relay.Constant][13] /* ty=Tensor[(128, 1, 1), float32] */ /* ty=Tensor[(128, 1, 1), float32] */, %add_rhs_scale_39, %add_rhs_zero_pt_39, out_dtype="int8");
  %83 = qnn.add(%81, %82, %add_lhs_scale_38, %add_lhs_zero_pt_38, %add_rhs_scale_39, %add_rhs_zero_pt_39, %add_out_scale_40, %add_out_zero_pt_40);
  %84 = qnn.dequantize(%83, %add_out_scale_40, %add_out_zero_pt_40);
  %85 = qnn.quantize(%84, %add_lhs_scale_46, %add_lhs_zero_pt_46, out_dtype="int8");
  %86 = qnn.quantize(%63, %conv2d_data_scale_41, %conv2d_data_zero_pt_41, out_dtype="int8");
  %87 = nn.pad(%86, pad_width=[[0, 0], [0, 0], [0, 0], [0, 0]]);
  %88 = qnn.quantize(meta[relay.Constant][14] /* ty=Tensor[(128, 64, 1, 1), float32] */ /* ty=Tensor[(128, 64, 1, 1), float32] */, %conv2d_weight_scale_42, %conv2d_weight_zero_pt_42, out_dtype="int8");
  %89 = qnn.conv2d(%87, %88, %conv2d_data_zero_pt_41, %conv2d_weight_zero_pt_42, %conv2d_data_scale_41, %conv2d_weight_scale_42, strides=[2, 2], padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1], out_dtype="int32");
  %90 = multiply(%conv2d_data_scale_41, %conv2d_weight_scale_42);
  %91 = qnn.dequantize(%89, %90, 0);
  %92 = qnn.quantize(%91, %add_lhs_scale_43, %add_lhs_zero_pt_43, out_dtype="int8");
  %93 = qnn.quantize(meta[relay.Constant][15] /* ty=Tensor[(128, 1, 1), float32] */ /* ty=Tensor[(128, 1, 1), float32] */, %add_rhs_scale_44, %add_rhs_zero_pt_44, out_dtype="int8");
  %94 = qnn.add(%92, %93, %add_lhs_scale_43, %add_lhs_zero_pt_43, %add_rhs_scale_44, %add_rhs_zero_pt_44, %add_out_scale_45, %add_out_zero_pt_45);
  %95 = qnn.dequantize(%94, %add_out_scale_45, %add_out_zero_pt_45);
  %96 = qnn.quantize(%95, %add_rhs_scale_47, %add_rhs_zero_pt_47, out_dtype="int8");
  %97 = qnn.add(%85, %96, %add_lhs_scale_46, %add_lhs_zero_pt_46, %add_rhs_scale_47, %add_rhs_zero_pt_47, %add_out_scale_48, %add_out_zero_pt_48);
  %98 = qnn.dequantize(%97, %add_out_scale_48, %add_out_zero_pt_48);
  %99 = nn.relu(%98);
  %100 = qnn.quantize(%99, %conv2d_data_scale_49, %conv2d_data_zero_pt_49, out_dtype="int8");
  %101 = nn.pad(%100, pad_width=[[0, 0], [0, 0], [1, 1], [1, 1]]);
  %102 = qnn.quantize(meta[relay.Constant][16] /* ty=Tensor[(128, 128, 3, 3), float32] */ /* ty=Tensor[(128, 128, 3, 3), float32] */, %conv2d_weight_scale_50, %conv2d_weight_zero_pt_50, out_dtype="int8");
  %103 = qnn.conv2d(%101, %102, %conv2d_data_zero_pt_49, %conv2d_weight_zero_pt_50, %conv2d_data_scale_49, %conv2d_weight_scale_50, padding=[0, 0, 0, 0], channels=128, kernel_size=[3, 3], out_dtype="int32");
  %104 = multiply(%conv2d_data_scale_49, %conv2d_weight_scale_50);
  %105 = qnn.dequantize(%103, %104, 0);
  %106 = qnn.quantize(%105, %add_lhs_scale_51, %add_lhs_zero_pt_51, out_dtype="int8");
  %107 = qnn.quantize(meta[relay.Constant][17] /* ty=Tensor[(128, 1, 1), float32] */ /* ty=Tensor[(128, 1, 1), float32] */, %add_rhs_scale_52, %add_rhs_zero_pt_52, out_dtype="int8");
  %108 = qnn.add(%106, %107, %add_lhs_scale_51, %add_lhs_zero_pt_51, %add_rhs_scale_52, %add_rhs_zero_pt_52, %add_out_scale_53, %add_out_zero_pt_53);
  %109 = qnn.dequantize(%108, %add_out_scale_53, %add_out_zero_pt_53);
  %110 = nn.relu(%109);
  %111 = qnn.quantize(%110, %conv2d_data_scale_54, %conv2d_data_zero_pt_54, out_dtype="int8");
  %112 = nn.pad(%111, pad_width=[[0, 0], [0, 0], [1, 1], [1, 1]]);
  %113 = qnn.quantize(meta[relay.Constant][18] /* ty=Tensor[(128, 128, 3, 3), float32] */ /* ty=Tensor[(128, 128, 3, 3), float32] */, %conv2d_weight_scale_55, %conv2d_weight_zero_pt_55, out_dtype="int8");
  %114 = qnn.conv2d(%112, %113, %conv2d_data_zero_pt_54, %conv2d_weight_zero_pt_55, %conv2d_data_scale_54, %conv2d_weight_scale_55, padding=[0, 0, 0, 0], channels=128, kernel_size=[3, 3], out_dtype="int32");
  %115 = multiply(%conv2d_data_scale_54, %conv2d_weight_scale_55);
  %116 = qnn.dequantize(%114, %115, 0);
  %117 = qnn.quantize(%116, %add_lhs_scale_56, %add_lhs_zero_pt_56, out_dtype="int8");
  %118 = qnn.quantize(meta[relay.Constant][19] /* ty=Tensor[(128, 1, 1), float32] */ /* ty=Tensor[(128, 1, 1), float32] */, %add_rhs_scale_57, %add_rhs_zero_pt_57, out_dtype="int8");
  %119 = qnn.add(%117, %118, %add_lhs_scale_56, %add_lhs_zero_pt_56, %add_rhs_scale_57, %add_rhs_zero_pt_57, %add_out_scale_58, %add_out_zero_pt_58);
  %120 = qnn.dequantize(%119, %add_out_scale_58, %add_out_zero_pt_58);
  %121 = qnn.quantize(%120, %add_lhs_scale_59, %add_lhs_zero_pt_59, out_dtype="int8");
  %122 = qnn.quantize(%99, %add_rhs_scale_60, %add_rhs_zero_pt_60, out_dtype="int8");
  %123 = qnn.add(%121, %122, %add_lhs_scale_59, %add_lhs_zero_pt_59, %add_rhs_scale_60, %add_rhs_zero_pt_60, %add_out_scale_61, %add_out_zero_pt_61);
  %124 = qnn.dequantize(%123, %add_out_scale_61, %add_out_zero_pt_61);
  %125 = nn.relu(%124);
  %126 = qnn.quantize(%125, %conv2d_data_scale_62, %conv2d_data_zero_pt_62, out_dtype="int8");
  %127 = nn.pad(%126, pad_width=[[0, 0], [0, 0], [1, 1], [1, 1]]);
  %128 = qnn.quantize(meta[relay.Constant][20] /* ty=Tensor[(256, 128, 3, 3), float32] */ /* ty=Tensor[(256, 128, 3, 3), float32] */, %conv2d_weight_scale_63, %conv2d_weight_zero_pt_63, out_dtype="int8");
  %129 = qnn.conv2d(%127, %128, %conv2d_data_zero_pt_62, %conv2d_weight_zero_pt_63, %conv2d_data_scale_62, %conv2d_weight_scale_63, strides=[2, 2], padding=[0, 0, 0, 0], channels=256, kernel_size=[3, 3], out_dtype="int32");
  %130 = multiply(%conv2d_data_scale_62, %conv2d_weight_scale_63);
  %131 = qnn.dequantize(%129, %130, 0);
  %132 = qnn.quantize(%131, %add_lhs_scale_64, %add_lhs_zero_pt_64, out_dtype="int8");
  %133 = qnn.quantize(meta[relay.Constant][21] /* ty=Tensor[(256, 1, 1), float32] */ /* ty=Tensor[(256, 1, 1), float32] */, %add_rhs_scale_65, %add_rhs_zero_pt_65, out_dtype="int8");
  %134 = qnn.add(%132, %133, %add_lhs_scale_64, %add_lhs_zero_pt_64, %add_rhs_scale_65, %add_rhs_zero_pt_65, %add_out_scale_66, %add_out_zero_pt_66);
  %135 = qnn.dequantize(%134, %add_out_scale_66, %add_out_zero_pt_66);
  %136 = nn.relu(%135);
  %137 = qnn.quantize(%136, %conv2d_data_scale_67, %conv2d_data_zero_pt_67, out_dtype="int8");
  %138 = nn.pad(%137, pad_width=[[0, 0], [0, 0], [1, 1], [1, 1]]);
  %139 = qnn.quantize(meta[relay.Constant][22] /* ty=Tensor[(256, 256, 3, 3), float32] */ /* ty=Tensor[(256, 256, 3, 3), float32] */, %conv2d_weight_scale_68, %conv2d_weight_zero_pt_68, out_dtype="int8");
  %140 = qnn.conv2d(%138, %139, %conv2d_data_zero_pt_67, %conv2d_weight_zero_pt_68, %conv2d_data_scale_67, %conv2d_weight_scale_68, padding=[0, 0, 0, 0], channels=256, kernel_size=[3, 3], out_dtype="int32");
  %141 = multiply(%conv2d_data_scale_67, %conv2d_weight_scale_68);
  %142 = qnn.dequantize(%140, %141, 0);
  %143 = qnn.quantize(%142, %add_lhs_scale_69, %add_lhs_zero_pt_69, out_dtype="int8");
  %144 = qnn.quantize(meta[relay.Constant][23] /* ty=Tensor[(256, 1, 1), float32] */ /* ty=Tensor[(256, 1, 1), float32] */, %add_rhs_scale_70, %add_rhs_zero_pt_70, out_dtype="int8");
  %145 = qnn.add(%143, %144, %add_lhs_scale_69, %add_lhs_zero_pt_69, %add_rhs_scale_70, %add_rhs_zero_pt_70, %add_out_scale_71, %add_out_zero_pt_71);
  %146 = qnn.dequantize(%145, %add_out_scale_71, %add_out_zero_pt_71);
  %147 = qnn.quantize(%146, %add_lhs_scale_77, %add_lhs_zero_pt_77, out_dtype="int8");
  %148 = qnn.quantize(%125, %conv2d_data_scale_72, %conv2d_data_zero_pt_72, out_dtype="int8");
  %149 = nn.pad(%148, pad_width=[[0, 0], [0, 0], [0, 0], [0, 0]]);
  %150 = qnn.quantize(meta[relay.Constant][24] /* ty=Tensor[(256, 128, 1, 1), float32] */ /* ty=Tensor[(256, 128, 1, 1), float32] */, %conv2d_weight_scale_73, %conv2d_weight_zero_pt_73, out_dtype="int8");
  %151 = qnn.conv2d(%149, %150, %conv2d_data_zero_pt_72, %conv2d_weight_zero_pt_73, %conv2d_data_scale_72, %conv2d_weight_scale_73, strides=[2, 2], padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1], out_dtype="int32");
  %152 = multiply(%conv2d_data_scale_72, %conv2d_weight_scale_73);
  %153 = qnn.dequantize(%151, %152, 0);
  %154 = qnn.quantize(%153, %add_lhs_scale_74, %add_lhs_zero_pt_74, out_dtype="int8");
  %155 = qnn.quantize(meta[relay.Constant][25] /* ty=Tensor[(256, 1, 1), float32] */ /* ty=Tensor[(256, 1, 1), float32] */, %add_rhs_scale_75, %add_rhs_zero_pt_75, out_dtype="int8");
  %156 = qnn.add(%154, %155, %add_lhs_scale_74, %add_lhs_zero_pt_74, %add_rhs_scale_75, %add_rhs_zero_pt_75, %add_out_scale_76, %add_out_zero_pt_76);
  %157 = qnn.dequantize(%156, %add_out_scale_76, %add_out_zero_pt_76);
  %158 = qnn.quantize(%157, %add_rhs_scale_78, %add_rhs_zero_pt_78, out_dtype="int8");
  %159 = qnn.add(%147, %158, %add_lhs_scale_77, %add_lhs_zero_pt_77, %add_rhs_scale_78, %add_rhs_zero_pt_78, %add_out_scale_79, %add_out_zero_pt_79);
  %160 = qnn.dequantize(%159, %add_out_scale_79, %add_out_zero_pt_79);
  %161 = nn.relu(%160);
  %162 = qnn.quantize(%161, %conv2d_data_scale_80, %conv2d_data_zero_pt_80, out_dtype="int8");
  %163 = nn.pad(%162, pad_width=[[0, 0], [0, 0], [1, 1], [1, 1]]);
  %164 = qnn.quantize(meta[relay.Constant][26] /* ty=Tensor[(256, 256, 3, 3), float32] */ /* ty=Tensor[(256, 256, 3, 3), float32] */, %conv2d_weight_scale_81, %conv2d_weight_zero_pt_81, out_dtype="int8");
  %165 = qnn.conv2d(%163, %164, %conv2d_data_zero_pt_80, %conv2d_weight_zero_pt_81, %conv2d_data_scale_80, %conv2d_weight_scale_81, padding=[0, 0, 0, 0], channels=256, kernel_size=[3, 3], out_dtype="int32");
  %166 = multiply(%conv2d_data_scale_80, %conv2d_weight_scale_81);
  %167 = qnn.dequantize(%165, %166, 0);
  %168 = qnn.quantize(%167, %add_lhs_scale_82, %add_lhs_zero_pt_82, out_dtype="int8");
  %169 = qnn.quantize(meta[relay.Constant][27] /* ty=Tensor[(256, 1, 1), float32] */ /* ty=Tensor[(256, 1, 1), float32] */, %add_rhs_scale_83, %add_rhs_zero_pt_83, out_dtype="int8");
  %170 = qnn.add(%168, %169, %add_lhs_scale_82, %add_lhs_zero_pt_82, %add_rhs_scale_83, %add_rhs_zero_pt_83, %add_out_scale_84, %add_out_zero_pt_84);
  %171 = qnn.dequantize(%170, %add_out_scale_84, %add_out_zero_pt_84);
  %172 = nn.relu(%171);
  %173 = qnn.quantize(%172, %conv2d_data_scale_85, %conv2d_data_zero_pt_85, out_dtype="int8");
  %174 = nn.pad(%173, pad_width=[[0, 0], [0, 0], [1, 1], [1, 1]]);
  %175 = qnn.quantize(meta[relay.Constant][28] /* ty=Tensor[(256, 256, 3, 3), float32] */ /* ty=Tensor[(256, 256, 3, 3), float32] */, %conv2d_weight_scale_86, %conv2d_weight_zero_pt_86, out_dtype="int8");
  %176 = qnn.conv2d(%174, %175, %conv2d_data_zero_pt_85, %conv2d_weight_zero_pt_86, %conv2d_data_scale_85, %conv2d_weight_scale_86, padding=[0, 0, 0, 0], channels=256, kernel_size=[3, 3], out_dtype="int32");
  %177 = multiply(%conv2d_data_scale_85, %conv2d_weight_scale_86);
  %178 = qnn.dequantize(%176, %177, 0);
  %179 = qnn.quantize(%178, %add_lhs_scale_87, %add_lhs_zero_pt_87, out_dtype="int8");
  %180 = qnn.quantize(meta[relay.Constant][29] /* ty=Tensor[(256, 1, 1), float32] */ /* ty=Tensor[(256, 1, 1), float32] */, %add_rhs_scale_88, %add_rhs_zero_pt_88, out_dtype="int8");
  %181 = qnn.add(%179, %180, %add_lhs_scale_87, %add_lhs_zero_pt_87, %add_rhs_scale_88, %add_rhs_zero_pt_88, %add_out_scale_89, %add_out_zero_pt_89);
  %182 = qnn.dequantize(%181, %add_out_scale_89, %add_out_zero_pt_89);
  %183 = qnn.quantize(%182, %add_lhs_scale_90, %add_lhs_zero_pt_90, out_dtype="int8");
  %184 = qnn.quantize(%161, %add_rhs_scale_91, %add_rhs_zero_pt_91, out_dtype="int8");
  %185 = qnn.add(%183, %184, %add_lhs_scale_90, %add_lhs_zero_pt_90, %add_rhs_scale_91, %add_rhs_zero_pt_91, %add_out_scale_92, %add_out_zero_pt_92);
  %186 = qnn.dequantize(%185, %add_out_scale_92, %add_out_zero_pt_92);
  %187 = nn.relu(%186);
  %188 = qnn.quantize(%187, %conv2d_data_scale_93, %conv2d_data_zero_pt_93, out_dtype="int8");
  %189 = nn.pad(%188, pad_width=[[0, 0], [0, 0], [1, 1], [1, 1]]);
  %190 = qnn.quantize(meta[relay.Constant][30] /* ty=Tensor[(512, 256, 3, 3), float32] */ /* ty=Tensor[(512, 256, 3, 3), float32] */, %conv2d_weight_scale_94, %conv2d_weight_zero_pt_94, out_dtype="int8");
  %191 = qnn.conv2d(%189, %190, %conv2d_data_zero_pt_93, %conv2d_weight_zero_pt_94, %conv2d_data_scale_93, %conv2d_weight_scale_94, strides=[2, 2], padding=[0, 0, 0, 0], channels=512, kernel_size=[3, 3], out_dtype="int32");
  %192 = multiply(%conv2d_data_scale_93, %conv2d_weight_scale_94);
  %193 = qnn.dequantize(%191, %192, 0);
  %194 = qnn.quantize(%193, %add_lhs_scale_95, %add_lhs_zero_pt_95, out_dtype="int8");
  %195 = qnn.quantize(meta[relay.Constant][31] /* ty=Tensor[(512, 1, 1), float32] */ /* ty=Tensor[(512, 1, 1), float32] */, %add_rhs_scale_96, %add_rhs_zero_pt_96, out_dtype="int8");
  %196 = qnn.add(%194, %195, %add_lhs_scale_95, %add_lhs_zero_pt_95, %add_rhs_scale_96, %add_rhs_zero_pt_96, %add_out_scale_97, %add_out_zero_pt_97);
  %197 = qnn.dequantize(%196, %add_out_scale_97, %add_out_zero_pt_97);
  %198 = nn.relu(%197);
  %199 = qnn.quantize(%198, %conv2d_data_scale_98, %conv2d_data_zero_pt_98, out_dtype="int8");
  %200 = nn.pad(%199, pad_width=[[0, 0], [0, 0], [1, 1], [1, 1]]);
  %201 = qnn.quantize(meta[relay.Constant][32] /* ty=Tensor[(512, 512, 3, 3), float32] */ /* ty=Tensor[(512, 512, 3, 3), float32] */, %conv2d_weight_scale_99, %conv2d_weight_zero_pt_99, out_dtype="int8");
  %202 = qnn.conv2d(%200, %201, %conv2d_data_zero_pt_98, %conv2d_weight_zero_pt_99, %conv2d_data_scale_98, %conv2d_weight_scale_99, padding=[0, 0, 0, 0], channels=512, kernel_size=[3, 3], out_dtype="int32");
  %203 = multiply(%conv2d_data_scale_98, %conv2d_weight_scale_99);
  %204 = qnn.dequantize(%202, %203, 0);
  %205 = qnn.quantize(%204, %add_lhs_scale_100, %add_lhs_zero_pt_100, out_dtype="int8");
  %206 = qnn.quantize(meta[relay.Constant][33] /* ty=Tensor[(512, 1, 1), float32] */ /* ty=Tensor[(512, 1, 1), float32] */, %add_rhs_scale_101, %add_rhs_zero_pt_101, out_dtype="int8");
  %207 = qnn.add(%205, %206, %add_lhs_scale_100, %add_lhs_zero_pt_100, %add_rhs_scale_101, %add_rhs_zero_pt_101, %add_out_scale_102, %add_out_zero_pt_102);
  %208 = qnn.dequantize(%207, %add_out_scale_102, %add_out_zero_pt_102);
  %209 = qnn.quantize(%208, %add_lhs_scale_108, %add_lhs_zero_pt_108, out_dtype="int8");
  %210 = qnn.quantize(%187, %conv2d_data_scale_103, %conv2d_data_zero_pt_103, out_dtype="int8");
  %211 = nn.pad(%210, pad_width=[[0, 0], [0, 0], [0, 0], [0, 0]]);
  %212 = qnn.quantize(meta[relay.Constant][34] /* ty=Tensor[(512, 256, 1, 1), float32] */ /* ty=Tensor[(512, 256, 1, 1), float32] */, %conv2d_weight_scale_104, %conv2d_weight_zero_pt_104, out_dtype="int8");
  %213 = qnn.conv2d(%211, %212, %conv2d_data_zero_pt_103, %conv2d_weight_zero_pt_104, %conv2d_data_scale_103, %conv2d_weight_scale_104, strides=[2, 2], padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1], out_dtype="int32");
  %214 = multiply(%conv2d_data_scale_103, %conv2d_weight_scale_104);
  %215 = qnn.dequantize(%213, %214, 0);
  %216 = qnn.quantize(%215, %add_lhs_scale_105, %add_lhs_zero_pt_105, out_dtype="int8");
  %217 = qnn.quantize(meta[relay.Constant][35] /* ty=Tensor[(512, 1, 1), float32] */ /* ty=Tensor[(512, 1, 1), float32] */, %add_rhs_scale_106, %add_rhs_zero_pt_106, out_dtype="int8");
  %218 = qnn.add(%216, %217, %add_lhs_scale_105, %add_lhs_zero_pt_105, %add_rhs_scale_106, %add_rhs_zero_pt_106, %add_out_scale_107, %add_out_zero_pt_107);
  %219 = qnn.dequantize(%218, %add_out_scale_107, %add_out_zero_pt_107);
  %220 = qnn.quantize(%219, %add_rhs_scale_109, %add_rhs_zero_pt_109, out_dtype="int8");
  %221 = qnn.add(%209, %220, %add_lhs_scale_108, %add_lhs_zero_pt_108, %add_rhs_scale_109, %add_rhs_zero_pt_109, %add_out_scale_110, %add_out_zero_pt_110);
  %222 = qnn.dequantize(%221, %add_out_scale_110, %add_out_zero_pt_110);
  %223 = nn.relu(%222);
  %224 = qnn.quantize(%223, %conv2d_data_scale_111, %conv2d_data_zero_pt_111, out_dtype="int8");
  %225 = nn.pad(%224, pad_width=[[0, 0], [0, 0], [1, 1], [1, 1]]);
  %226 = qnn.quantize(meta[relay.Constant][36] /* ty=Tensor[(512, 512, 3, 3), float32] */ /* ty=Tensor[(512, 512, 3, 3), float32] */, %conv2d_weight_scale_112, %conv2d_weight_zero_pt_112, out_dtype="int8");
  %227 = qnn.conv2d(%225, %226, %conv2d_data_zero_pt_111, %conv2d_weight_zero_pt_112, %conv2d_data_scale_111, %conv2d_weight_scale_112, padding=[0, 0, 0, 0], channels=512, kernel_size=[3, 3], out_dtype="int32");
  %228 = multiply(%conv2d_data_scale_111, %conv2d_weight_scale_112);
  %229 = qnn.dequantize(%227, %228, 0);
  %230 = qnn.quantize(%229, %add_lhs_scale_113, %add_lhs_zero_pt_113, out_dtype="int8");
  %231 = qnn.quantize(meta[relay.Constant][37] /* ty=Tensor[(512, 1, 1), float32] */ /* ty=Tensor[(512, 1, 1), float32] */, %add_rhs_scale_114, %add_rhs_zero_pt_114, out_dtype="int8");
  %232 = qnn.add(%230, %231, %add_lhs_scale_113, %add_lhs_zero_pt_113, %add_rhs_scale_114, %add_rhs_zero_pt_114, %add_out_scale_115, %add_out_zero_pt_115);
  %233 = qnn.dequantize(%232, %add_out_scale_115, %add_out_zero_pt_115);
  %234 = nn.relu(%233);
  %235 = qnn.quantize(%234, %conv2d_data_scale_116, %conv2d_data_zero_pt_116, out_dtype="int8");
  %236 = nn.pad(%235, pad_width=[[0, 0], [0, 0], [1, 1], [1, 1]]);
  %237 = qnn.quantize(meta[relay.Constant][38] /* ty=Tensor[(512, 512, 3, 3), float32] */ /* ty=Tensor[(512, 512, 3, 3), float32] */, %conv2d_weight_scale_117, %conv2d_weight_zero_pt_117, out_dtype="int8");
  %238 = qnn.conv2d(%236, %237, %conv2d_data_zero_pt_116, %conv2d_weight_zero_pt_117, %conv2d_data_scale_116, %conv2d_weight_scale_117, padding=[0, 0, 0, 0], channels=512, kernel_size=[3, 3], out_dtype="int32");
  %239 = multiply(%conv2d_data_scale_116, %conv2d_weight_scale_117);
  %240 = qnn.dequantize(%238, %239, 0);
  %241 = qnn.quantize(%240, %add_lhs_scale_118, %add_lhs_zero_pt_118, out_dtype="int8");
  %242 = qnn.quantize(meta[relay.Constant][39] /* ty=Tensor[(512, 1, 1), float32] */ /* ty=Tensor[(512, 1, 1), float32] */, %add_rhs_scale_119, %add_rhs_zero_pt_119, out_dtype="int8");
  %243 = qnn.add(%241, %242, %add_lhs_scale_118, %add_lhs_zero_pt_118, %add_rhs_scale_119, %add_rhs_zero_pt_119, %add_out_scale_120, %add_out_zero_pt_120);
  %244 = qnn.dequantize(%243, %add_out_scale_120, %add_out_zero_pt_120);
  %245 = qnn.quantize(%244, %add_lhs_scale_121, %add_lhs_zero_pt_121, out_dtype="int8");
  %246 = qnn.quantize(%223, %add_rhs_scale_122, %add_rhs_zero_pt_122, out_dtype="int8");
  %247 = qnn.add(%245, %246, %add_lhs_scale_121, %add_lhs_zero_pt_121, %add_rhs_scale_122, %add_rhs_zero_pt_122, %add_out_scale_123, %add_out_zero_pt_123);
  %248 = qnn.dequantize(%247, %add_out_scale_123, %add_out_zero_pt_123);
  %249 = nn.relu(%248);
  %250 = nn.adaptive_avg_pool2d(%249, output_size=[1, 1]);
  %251 = nn.batch_flatten(%250);
  %252 = qnn.quantize(%251, %dense_data_scale_124, %dense_data_zero_pt_124, out_dtype="int8");
  %253 = qnn.quantize(meta[relay.Constant][40] /* ty=Tensor[(1000, 512), float32] */ /* ty=Tensor[(1000, 512), float32] */, %dense_weight_scale_125, %dense_weight_zero_pt_125, out_dtype="int8");
  %254 = qnn.dense(%252, %253, %dense_data_zero_pt_124, %dense_weight_zero_pt_125, %dense_data_scale_124, %dense_weight_scale_125, units=1000, out_dtype="int32");
  %255 = multiply(%dense_data_scale_124, %dense_weight_scale_125);
  %256 = qnn.dequantize(%254, %255, 0);
  %257 = qnn.quantize(%256, %add_lhs_scale_126, %add_lhs_zero_pt_126, out_dtype="int8");
  %258 = qnn.quantize(meta[relay.Constant][41] /* ty=Tensor[(1000), float32] */ /* ty=Tensor[(1000), float32] */, %add_rhs_scale_127, %add_rhs_zero_pt_127, out_dtype="int8");
  %259 = qnn.add(%257, %258, %add_lhs_scale_126, %add_lhs_zero_pt_126, %add_rhs_scale_127, %add_rhs_zero_pt_127, %add_out_scale_128, %add_out_zero_pt_128);
  qnn.dequantize(%259, %add_out_scale_128, %add_out_zero_pt_128)
}

